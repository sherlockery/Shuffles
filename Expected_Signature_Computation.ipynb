{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTi6JJhz2L6O"
      },
      "outputs": [],
      "source": [
        "# !pip install git+https://github.com/crispitagorico/sigkernel.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.linalg\n",
        "import functools, sys, os, math, itertools, operator, six\n",
        "from sympy.utilities.iterables import multiset_permutations, ordered_partitions, kbins\n",
        "from sympy.ntheory import mobius, divisors\n",
        "from sympy import Rational\n",
        "import sympy\n",
        "import unittest\n",
        "import pyparsing\n",
        "\n",
        "#This module provides free Lie algebra calculations in the manner of\n",
        "#the first part of Reutenauer, on an alphabet of positive integers and\n",
        "#using float (or sympy expressions) as the \"field\" K.\n",
        "#Hopefully the code and definitions of most functions look similar.\n",
        "#It is not written to be efficient, but to be hackable.\n",
        "#Works on Python 2 or 3, but not caring about inefficiencies caused by\n",
        "#things like \"range\" and \"items\" on Python 2\n",
        "\n",
        "#The test() function at the bottom of this file illustrates the kind of calculations you can do.\n",
        "\n",
        "#The main objects include Elt (which represents an element of tensor space)\n",
        "#and EltElt (which represents Elts tensored together).\n",
        "#This code is written defensively around them: functions do not modify\n",
        "#such inputs, but they do not assume that their inputs are immutable.\n",
        "#For example, return values do not share references to parts of their inputs.\n",
        "#Words and coefficients, however, are considered immutable.\n",
        "#The Elt object represents both an element of tensor space and its dual\n",
        "#(through the function dotprod), which\n",
        "#provides flexibility but is arguably not algebraically nice.\n",
        "\n",
        "#If you know in advance that you only care about the answer up to a certain depth\n",
        "# (number of levels) then you can save a lot of time in lots of functions. Most of\n",
        "# the runtime of product operations is often in higher levels. These operations take a\n",
        "# maxLevel parameter. You can use the context manager MaxLevelContext to set it everywhere.\n",
        "\n",
        "#There's a simple string representation of an Elt\n",
        "#(which you go *to* via pretty() and *from* via parse() )\n",
        "#in which coefficients are surrounded by square brackets.\n",
        "#For example \"[1]\" is the unit element and \"[3]12-[3]21\" is a multiple of signed area.\n",
        "\n",
        "#If you want to use your own coefficient as K, make it something hashable,\n",
        "#something with operators +, -, * and ==,\n",
        "#and make sure * accepts float and int as well as itself\n",
        "#and change the next six functions.\n",
        "#The \"distance\" function won't work, but you can sort that yourself.\n",
        "#By default, the coefficients are float, which is simple. If you use the UseRationalContext\n",
        "#context manager, you get sympy.Rational.\n",
        "def assert_coefficient(c):\n",
        "    #this should accept float and int as well as a custom coefficient\n",
        "    #note that isinstance(c,float) includes numpy floating point types as well as actual float\n",
        "    assert isinstance(c, (float, int, sympy.Basic)), (c, type(c))\n",
        "    #assert type(c) in (float, int), c\n",
        "def unit_coefficient():\n",
        "    return 1\n",
        "def zero_coefficient():\n",
        "    return 0\n",
        "def isunit_coefficient(c):#should accept float and int as well as custom coefficient\n",
        "    return 1==c\n",
        "def iszero_coefficient(c):#should accept float and int as well as custom coefficient\n",
        "    return 0==c\n",
        "\n",
        "_defaultUseRational=False\n",
        "def reciprocate_integer(i,useRational=None):\n",
        "    \"\"\"This function takes an int i and a suggestion whether to use rationals\n",
        "    instead of floats. It returns 1/i as a coefficient.\"\"\"\n",
        "    if useRational is None:\n",
        "        useRational=_defaultUseRational\n",
        "    if useRational:\n",
        "        return Rational(1,i)\n",
        "    return 1.0/i\n",
        "\n",
        "_defaultMaxLevel=None\n",
        "def _getMaxLevel(level):\n",
        "    if level is None:\n",
        "        return _defaultMaxLevel\n",
        "    return level\n",
        "\n",
        "class Word:\n",
        "    \"\"\"The alphabet is int. This class represents an immutable word on the alphabet\"\"\"\n",
        "    def __init__(self, letters):\n",
        "        self.letters=tuple(int(i) for i in letters)\n",
        "    def __hash__(self):\n",
        "        return hash(self.letters)\n",
        "    def __eq__(self,other):\n",
        "        return self.letters==other.letters\n",
        "    def __repr__(self):\n",
        "        return \"\".join(str(i) for i in self.letters)\n",
        "    def crudeNumber(self):\n",
        "        \"\"\"for small d, the integer whose decimal representation is str(self)\"\"\"\n",
        "        return functools.reduce(lambda x, y: 10*x+y, self.letters)\n",
        "emptyWord=Word([])\n",
        "def concatenate(a,b):\n",
        "    assert isinstance(a,Word) and isinstance(b,Word), (a,b)\n",
        "    return Word(a.letters+b.letters)\n",
        "\n",
        "#element of tensor space\n",
        "class Elt:\n",
        "    \"\"\"An element of the tensor algebra on the alphabet.\n",
        "       data is a list (one for each level) of dictionaries word->coefficient.\n",
        "       The * operator is only used for multiplication by a scalar\n",
        "    \"\"\"\n",
        "    def __init__(self,data):\n",
        "        assert type(data)==list, data\n",
        "        self.data=data\n",
        "    def __hash__(self):\n",
        "        #(We don't rely on hashability of Elt in this file,\n",
        "        #but it could be useful.\n",
        "        #This is a basic implementation, not perfect because extra empty\n",
        "        #levels affect the hash but not ==.\n",
        "        return hash( tuple( frozenset(level_dict.items()) for level_dict in self.data) )\n",
        "    def __eq__(self,other):\n",
        "        #return self.data==other.data\n",
        "        assert isinstance(other,Elt), other\n",
        "        for a,b in six.moves.zip_longest(self.data, other.data,fillvalue=dict()):\n",
        "            for k,v in a.items():\n",
        "                if v!=b.get(k,0):\n",
        "                    return False\n",
        "            for k,v in b.items():\n",
        "                if k not in a and not iszero_coefficient(v):\n",
        "                    return False\n",
        "        return True\n",
        "    def __repr__(self):\n",
        "        return \"E\"+str(self.data)\n",
        "    def __rmul__(self, scale):\n",
        "        assert_coefficient(scale)\n",
        "        return self*scale\n",
        "    def __mul__(self, scale):\n",
        "        assert_coefficient(scale)\n",
        "        if iszero_coefficient(scale):\n",
        "            return zeroElt\n",
        "        out=[{k:scale*v\n",
        "              for k,v in x.items()}\n",
        "             for x in self.data]\n",
        "        return Elt(out)\n",
        "    def __add__(self, b):\n",
        "        assert isinstance(b,Elt), b\n",
        "        if len(self.data)<len(b.data):\n",
        "            return b+self\n",
        "        out=[i.copy() for i in self.data]\n",
        "        for level,d in enumerate(b.data):\n",
        "            for w,v in d.items():\n",
        "                _increment_value_in_dict_to_coeff(out[level],w,v)\n",
        "        return Elt(out)\n",
        "    def __sub__(self,b):\n",
        "        assert isinstance(b,Elt), b\n",
        "        return self+(-1*b)\n",
        "    def __neg__(self):\n",
        "        return -1*self\n",
        "    def truncatedToLevel(self, level):\n",
        "        return Elt([i.copy() for i in self.data[:level+1]])\n",
        "    def restrictedToLevel(self, level):\n",
        "        if len(self.data)<level+1:\n",
        "            return Elt([dict()])\n",
        "        o=[dict() for i in range(1+level)]\n",
        "        o[-1]=self.data[level].copy()\n",
        "        return Elt(o)\n",
        "    def coeffApply(self,f):\n",
        "        \"\"\"return a new object where f has been applied to all coefficients\"\"\"\n",
        "        out=[{k:f(v)\n",
        "          for k,v in x.items()}\n",
        "           for x in self.data]\n",
        "        return Elt(out)\n",
        "    def maxLetter(self):\n",
        "        \"\"\"get the maximum letter used\"\"\"\n",
        "        l=1\n",
        "        for i in self.data:\n",
        "            for j in i:\n",
        "                for k in j.letters:\n",
        "                    if l<k:\n",
        "                        l=k\n",
        "        return l\n",
        "    def pretty(self, dp=15, tol=None, maxLevel=None):\n",
        "        \"\"\"a pretty string representation\"\"\"\n",
        "        return self._pretty(dp=dp, tol=tol, p=None, maxLevel=maxLevel)\n",
        "    def _pretty(self, dp, tol, p, maxLevel=None):\n",
        "        #This could be made __repr__ if we trust it\n",
        "        maxLevel=_getMaxLevel(maxLevel)\n",
        "        s=(self if maxLevel is None else self.truncatedToLevel(maxLevel))\n",
        "        if tol is None:\n",
        "            tol=10**(-dp)\n",
        "        if dp is None:\n",
        "            formatString = \"[{}]\"\n",
        "        else:\n",
        "            formatString = \"[{:.\"+str(dp)+\"g}]\"\n",
        "        def item(i,j):\n",
        "            number = isinstance(j,(float,sympy.Float, int))\n",
        "            if number and math.fabs(j)<tol:\n",
        "                return \"\"\n",
        "            sign = (\"+\" if (not number or j>=0) else \"-\")\n",
        "            omitCoeff = len(i.letters)!=0 and (j==1 or j==-1)\n",
        "            #numpy floats inherit from float\n",
        "            formatString2Use = formatString if isinstance(j,(float,sympy.Float)) else \"[{}]\"\n",
        "            coeff = (\"\" if omitCoeff else formatString2Use.format(j if sign==\"+\" else -j))\n",
        "            if len(i.letters)!=0 and coeff==\"[1]\":\n",
        "                coeff=\"\"\n",
        "            lets = \"\".join(str(j) for j in i.letters)\n",
        "            return sign+coeff+lets\n",
        "        if p is None:\n",
        "            o= \"\".join(item(i,a[i]) for a in s.data for i in sorted(a,key=lambda x:x.letters))\n",
        "            if len(o)>0 and o[0]==\"+\":\n",
        "                return o[1:]\n",
        "            return o\n",
        "        else:\n",
        "            first=True\n",
        "            for a in s.data:\n",
        "                for i in sorted(a, key=lambda x:x.letters):\n",
        "                    it = item(i, a[i])\n",
        "                    if first and len(it)>0 and it[0]==\"+\":\n",
        "                        it=it[1:]\n",
        "                    if not first:\n",
        "                        p.breakable('')\n",
        "                    if len(it)>0:\n",
        "                        first=False\n",
        "                        p.text(it)\n",
        "    def _repr_pretty_(self, p, cycle):\n",
        "        \"\"\"enable IPython pretty output\"\"\"\n",
        "        self._pretty(dp=15, tol=None, p=p)\n",
        "    def prettySympy(self):\n",
        "        o=\"\"\n",
        "        for lev in self.data:\n",
        "            for k in sorted(lev,key=lambda x:x.letters):\n",
        "                vv=sympy.expand(lev[k])\n",
        "                if vv!=0:\n",
        "                    o=o+(\"+[{}]{}\".format(vv,k))\n",
        "        if len(o)>0 and o[0]==\"+\":\n",
        "            return o[1:]\n",
        "        return o\n",
        "        \n",
        "\n",
        "#TODO: almost anywhere this function is used in a loop\n",
        "#is an optimisation opportunity\n",
        "def word2Elt(word):\n",
        "    if type(word) in (str,tuple):\n",
        "        word=Word(word)\n",
        "    assert isinstance(word,Word),word\n",
        "    a=[dict() for i in range(1+len(word.letters))]\n",
        "    a[-1]={word:unit_coefficient()}\n",
        "    return Elt(a)\n",
        "def letter2Elt(letter):\n",
        "    return Elt([dict(),{Word((letter,)):unit_coefficient()}])\n",
        "    \n",
        "unitElt = Elt([{emptyWord:unit_coefficient()}])\n",
        "zeroElt = Elt([{emptyWord:zero_coefficient()}])\n",
        "\n",
        "def removeTinies(a):\n",
        "    \"\"\"a version of an Elt with tiny elements removed\"\"\"\n",
        "    assert isinstance(a,Elt), a\n",
        "    d=[{k:v for k,v in i.items() if math.fabs(v)>1e-15} for i in a.data]\n",
        "    return Elt(d)\n",
        "    \n",
        "def wordIter(d,m, topOnly=False, asNumbers=False):\n",
        "    \"\"\"return all words with up to or exactly m of the  d letters\"\"\"\n",
        "    from itertools import chain, product\n",
        "    alphabet=range(1,d+1) if asNumbers else \"123456789\"[:d]\n",
        "    if topOnly:\n",
        "        return product(alphabet, repeat=m)\n",
        "    it=chain.from_iterable(product(alphabet, repeat=r) for r in range(m+1))\n",
        "    return it\n",
        "    \n",
        "def randomElt(d,m,maxi=None):\n",
        "    \"\"\"a random Elt on d letters with m levels. If maxi not given, uniform[0,1] coeffs.\"\"\"\n",
        "    letters=range(1,d+1)\n",
        "    ran = lambda:np.random.rand() if maxi is None else np.random.randint(maxi)\n",
        "    out=[{Word(key):ran() for key in itertools.product(letters,repeat=lev)}\n",
        "              for lev in range(0,m+1)]\n",
        "    return Elt(out)\n",
        "\n",
        "class EltElt:\n",
        "    \"\"\"An element of the tensor product of the tensor algebra n times with itself.\n",
        "       data is a dictionary of (word,word,...)->coefficient\"\"\"\n",
        "    def __init__(self, data, n):\n",
        "        self.n=n\n",
        "        assert type(data)==dict, data\n",
        "        for k,v in data.items():\n",
        "            assert type(k)==tuple and len(k)==n\n",
        "            for i in k:\n",
        "                assert isinstance(i,Word),(data,n,i,k)\n",
        "        self.data=data\n",
        "    def __eq__(self,other):\n",
        "        return self.data==other.data\n",
        "    def __repr__(self):\n",
        "        return \"EE\"+str(self.data)\n",
        "    def get_deg(self):\n",
        "        if 0==len(self.data):\n",
        "            return 0\n",
        "        return max(sum(len(i.letters) for i in k) for k in self.data)\n",
        "    def __rmul__(self, scale):\n",
        "        assert_coefficient(scale)\n",
        "        return self*scale\n",
        "    def __mul__(self, scale):\n",
        "        assert_coefficient(scale)\n",
        "        if scale==0:\n",
        "            return EltElt(dict(),self.n)\n",
        "        out={k:scale*v\n",
        "              for k,v in self.data.items()}\n",
        "        return EltElt(out,self.n)\n",
        "    def __add__(self, b):\n",
        "        assert isinstance(b,EltElt), (b)\n",
        "        assert self.n == b.n\n",
        "        out=self.data.copy()\n",
        "        for k,v in b.data.items():\n",
        "            _increment_value_in_dict_to_coeff(out,k,v)\n",
        "        return EltElt(out,self.n)\n",
        "    def __neg__(self):\n",
        "        return -1*self\n",
        "    def __sub__(self,b):\n",
        "        assert isinstance(b,EltElt), b\n",
        "        assert self.n == b.n\n",
        "        return self+(-1*b)\n",
        "    def contract(self, a, b, simplify=True):\n",
        "        \"\"\"Tensor contraction. Return new EltElt where\n",
        "        the ath and bth element (starting from 1) have been contracted.\n",
        "        If simplify is True, return a coefficient or an Elt if possible\"\"\"\n",
        "        assert 1<=a<=self.n\n",
        "        assert 1<=b<=self.n\n",
        "        assert a!=b\n",
        "        if a > b:\n",
        "            b, a = a,b\n",
        "        d = {}\n",
        "        for k,v in self.data.items():\n",
        "             if k[a-1]==k[b-1]:\n",
        "                 key=k[:a-1]+k[a:b-1]+k[b:]\n",
        "                 _increment_value_in_dict_to_coeff(d, key, v)\n",
        "        o=EltElt(d,self.n-2)\n",
        "        if simplify and o.n==0:\n",
        "                return o.as_coefficient()\n",
        "        if simplify and o.n==1:\n",
        "            return o.as_Elt()\n",
        "        return o\n",
        "    def as_Elt(self):\n",
        "        \"\"\"If we are equivalent to just an Elt, return it\"\"\"\n",
        "        assert self.n == 1\n",
        "        o=functools.reduce(operator.add,(word2Elt(k)*v for (k,),v in self.data.items()))\n",
        "        return o\n",
        "    def as_coefficient(self):\n",
        "        \"\"\"If we are equivalent to just a coefficient, return it\"\"\"\n",
        "        assert self.n == 0\n",
        "        [o]=self.data.values()\n",
        "        return o\n",
        "    def truncatedToTotalLength(self,total):\n",
        "        out={k:v for k,v in self.data.items() if sum(len(i.letters) for i in k)<=total}\n",
        "        return EltElt(out,self.n)\n",
        "    def truncatedToLengths(self,lengths):\n",
        "        \"\"\"remove components where nth elt longer than lengths[n]\"\"\"\n",
        "        assert self.n == len(lengths)\n",
        "        out={k:v for k,v in self.data.items() \n",
        "             if all(j is None or len(i.letters)<=j for i,j in zip(k,lengths))}\n",
        "        return EltElt(out,self.n)\n",
        "    def restrictedToLengths(self,lengths):\n",
        "        \"\"\"remove components unless nth elt's length is lengths[n]\"\"\"\n",
        "        assert self.n == len(lengths)\n",
        "        out={k:v for k,v in self.data.items() \n",
        "             if all(j is None or len(i.letters)==j for i,j in zip(k,lengths))}\n",
        "        return EltElt(out,self.n)\n",
        "    def _key(self, x):\n",
        "        length = sum(len(aa.letters) for aa in x)\n",
        "        return (length,tuple(aa.letters for aa in x))\n",
        "    def _format(self, i):\n",
        "        if isinstance(self.data[i],(float, sympy.Float, int)):\n",
        "            return \"{:+}{}\".format(self.data[i],i)\n",
        "        return \"+{}{}\".format(self.data[i],i)\n",
        "    def pretty(self):\n",
        "        a=sorted(self.data, key=self._key)\n",
        "        #return [(self.data[i],i) for i in a]\n",
        "        return \" \".join(self._format(i) for i in a)\n",
        "    def _repr_pretty_(self, p, cycle):\n",
        "        \"\"\"enable IPython pretty output\"\"\"\n",
        "        for i in sorted(self.data, key=self._key):\n",
        "            p.text(self._format(i))\n",
        "            p.breakable(' ')\n",
        "\n",
        "def get_coefficient(a,word):\n",
        "    \"\"\"return the coefficient of the Word word in the Elt a\"\"\"\n",
        "    assert isinstance(a,Elt),a\n",
        "    assert isinstance(word,Word),word\n",
        "    level=len(word.letters)\n",
        "    if level<len(a.data):\n",
        "        return a.data[level].get(word,zero_coefficient())\n",
        "    return zero_coefficient()\n",
        "\n",
        "def epsilon_numeric(a):\n",
        "    \"\"\"The coefficient of the empty word in the Elt a\"\"\"\n",
        "    assert isinstance(a,Elt),a\n",
        "    if len(a.data)==0 or emptyWord not in a.data[0]:\n",
        "        return 0\n",
        "    return a.data[0][emptyWord]\n",
        "\n",
        "def epsilon(a):\n",
        "    \"\"\"The coefficient of the empty word in the Elt a, as an Elt\"\"\"\n",
        "    assert isinstance(a,Elt),a\n",
        "    return Elt(a.data[:1])\n",
        "\n",
        "def _increment_value_in_dict_to_coeff(dict_,k,v):\n",
        "    if k in dict_:\n",
        "        if iszero_coefficient(dict_[k]+v):\n",
        "            del dict_[k]\n",
        "        else:\n",
        "            dict_[k]+=v\n",
        "    elif not iszero_coefficient(v):\n",
        "        dict_[k]=v\n",
        "\n",
        "def dotprod(a,b):\n",
        "    \"\"\"The scalar product of the Elts a and b in the word basis\"\"\"\n",
        "    assert isinstance(a,Elt) and isinstance(b,Elt), (a,b)\n",
        "    out=zero_coefficient()\n",
        "    for x,y in zip(a.data,b.data):\n",
        "        for k in x:\n",
        "            if k in y:\n",
        "                out += x[k]*y[k]\n",
        "    return out\n",
        "\n",
        "def make_dual(a, returnElt=True):\n",
        "    \"\"\"Turn the Elt a into the function mapping b to dotprod(a,b)\n",
        "    We use Elts both for tensor space and its dual, so this makes sense.\n",
        "    Returning an Elt by default makes sense because can pass to tensorProductFunctions\"\"\"\n",
        "    #alternative - let conc take coefficients as well as Elts.\n",
        "    #c.f. EltElt's contract method\n",
        "    assert isinstance(a,Elt), a\n",
        "    def loc_dual(b):\n",
        "        d=dotprod(a,b)\n",
        "        if returnElt:\n",
        "            return d*unitElt\n",
        "        return d\n",
        "    return loc_dual\n",
        "\n",
        "def distance(a,b):\n",
        "    \"\"\"The distance between the Elts a and b in the word basis\"\"\"\n",
        "    assert isinstance(a,Elt) and isinstance(b,Elt), (a,b)\n",
        "    d=a-b\n",
        "    return math.sqrt(dotprod(d,d))\n",
        "\n",
        "def concatenationProduct(a,b,maxLevel=None):\n",
        "    \"\"\"The concatenation product of the Elts a and b. \n",
        "    This is the _internal_ tensor product in tensor space.\n",
        "    Levels above maxLevel, if provided, are ignored.\"\"\"\n",
        "    assert isinstance(a,Elt) and isinstance(b,Elt), (a,b)\n",
        "    topLevel = (len(a.data)-1)+(len(b.data)-1)\n",
        "    maxLevel = _getMaxLevel(maxLevel)\n",
        "    if maxLevel is None or maxLevel>topLevel:\n",
        "        maxLevel = topLevel\n",
        "    out=[dict() for i in range(maxLevel+1)]\n",
        "    for level in range(0,maxLevel+1):\n",
        "        for alevel in range(0,min(level+1,len(a.data))):\n",
        "            blevel=level-alevel\n",
        "            if blevel >= len(b.data) or b.data[blevel] is None or a.data[alevel] is None:\n",
        "                continue\n",
        "            for l1,l2 in a.data[alevel].items():\n",
        "                for r1,r2 in b.data[blevel].items():\n",
        "                    prod=l2*r2\n",
        "                    w = concatenate(l1,r1)\n",
        "                    _increment_value_in_dict_to_coeff(out[level],w,prod)\n",
        "    return Elt(out)\n",
        "\n",
        "def concatenationProductMany(a, maxLevel=None):\n",
        "    \"\"\"The concatenation product of many Elts (in the iterable a) all together\"\"\"\n",
        "    return functools.reduce(\n",
        "        lambda x,y : concatenationProduct(x,y,maxLevel),a)\n",
        "\n",
        "def shuffleProduct(a,b,maxLevel=None):\n",
        "    \"\"\"The shuffle product of two Elts\"\"\"\n",
        "    assert isinstance(a,Elt) and isinstance(b,Elt), (a,b)\n",
        "    topLevel = (len(a.data)-1)+(len(b.data)-1)\n",
        "    maxLevel = _getMaxLevel(maxLevel)\n",
        "    if maxLevel is None or maxLevel>topLevel:\n",
        "        maxLevel = topLevel\n",
        "    out=[dict() for i in range(maxLevel+1)]\n",
        "    for level in range(0,maxLevel+1):\n",
        "        for alevel in range(0,min(level+1,len(a.data))):\n",
        "            blevel=level-alevel\n",
        "            if blevel >= len(b.data) or b.data[blevel] is None or a.data[alevel] is None:\n",
        "                continue\n",
        "            source=(0,)*alevel + (1,)*blevel\n",
        "            for l1,l2 in a.data[alevel].items():\n",
        "                for r1,r2 in b.data[blevel].items():\n",
        "                    prod=l2*r2\n",
        "                    out_=np.zeros(level,dtype=\"int32\")\n",
        "                    if level==0:\n",
        "                        _increment_value_in_dict_to_coeff(out[0],emptyWord,prod)\n",
        "                    else:\n",
        "                        for mask in multiset_permutations(source):\n",
        "                            mask=np.array(mask)\n",
        "                            np.place(out_,1-mask,l1.letters)\n",
        "                            np.place(out_,mask,r1.letters)\n",
        "                            w = Word(out_)\n",
        "                            _increment_value_in_dict_to_coeff(out[level],w,prod)\n",
        "    return Elt(out)\n",
        "\n",
        "def shuffleProductMany(a, maxLevel=None):\n",
        "    \"\"\"The shuffle product of many Elts (in the iterable a) all together\"\"\"\n",
        "    return functools.reduce(\n",
        "        lambda x,y : shuffleProduct(x,y,maxLevel),a)\n",
        "\n",
        "def rightHalfShuffleProduct(a,b,maxLevel=None):\n",
        "    \"\"\"For two words a and b, their rightHalfShuffle is those shuffles\n",
        "    of a and b for which the last element is the last element of b.\n",
        "    This is extended to a bilinear operation on Elts.\n",
        "    If c is a letter then rightHalfShuffleProduct(a,bc) is (a shuffle b)c.\n",
        "    Usually (a shuffle b) == rightHalfShuffleProduct(a,b)+rightHalfShuffleProduct(b,a) (*)\n",
        "    In the current implementation, rightHalfShuffleProduct(a,b) is zero if b is the empty word,\n",
        "    even if a is the empty word.\n",
        "    Note that this means that (*) is violated if a and b are both the empty word.\n",
        "    This operation is often denoted $\\mathbin{\\succ}$, being a dendriform algebra operation.\n",
        "    It is not mentioned in the book.\"\"\"\n",
        "\n",
        "    assert isinstance(a,Elt) and isinstance(b,Elt), (a,b)\n",
        "    topLevel = (len(a.data)-1)+(len(b.data)-1)\n",
        "    maxLevel = _getMaxLevel(maxLevel)\n",
        "    if maxLevel is None or maxLevel>topLevel:\n",
        "        maxLevel = topLevel\n",
        "    out=[dict() for i in range(maxLevel+1)]\n",
        "    for level in range(0,maxLevel+1):\n",
        "        for alevel in range(0,min(level+1,len(a.data))):\n",
        "            blevel=level-alevel\n",
        "            if blevel >= len(b.data) or b.data[blevel] is None or a.data[alevel] is None:\n",
        "                continue\n",
        "            if blevel ==0:\n",
        "                continue\n",
        "            source=(0,)*alevel + (1,)*(blevel-1)\n",
        "            for l1,l2 in a.data[alevel].items():\n",
        "                for r1,r2 in b.data[blevel].items():\n",
        "                    prod=l2*r2\n",
        "                    out_=np.zeros(level,dtype=\"int32\")\n",
        "                    if level==1:#so r1 is a single letter\n",
        "                        _increment_value_in_dict_to_coeff(out[1],r1,prod)\n",
        "                    else:\n",
        "                        for mask in multiset_permutations(source):\n",
        "                            mask=np.array(mask+[1,])\n",
        "                            np.place(out_,1-mask,l1.letters)\n",
        "                            np.place(out_,mask,r1.letters)\n",
        "                            w = Word(out_)\n",
        "                            _increment_value_in_dict_to_coeff(out[level],w,prod)\n",
        "    return Elt(out)\n",
        "\n",
        "def leftHalfShuffleProduct(a,b,maxLevel=None):\n",
        "    \"\"\"For two words a and b, their leftHalfShuffle is those shuffles\n",
        "    of a and b for which the first element is the first element of a.\n",
        "    This is extended to a bilinear operation on Elts.\n",
        "    If c is a letter then leftHalfShuffleProduct(ab,c) is a(b shuffle c).\n",
        "    Usually (a shuffle b) == leftHalfShuffleProduct(a,b)+leftHalfShuffleProduct(b,a) (*)\n",
        "    In the current implementation, leftHalfShuffleProduct(a,b) is zero if a is the empty word,\n",
        "    even if b is the empty word.\n",
        "    Note that this means that (*) is violated if a and b are both the empty word.\n",
        "    This operation might be denoted $\\mathbin{\\prec}$, being a dendriform algebra operation.\n",
        "    It is not mentioned in the book.\"\"\"\n",
        "\n",
        "    assert isinstance(a,Elt) and isinstance(b,Elt), (a,b)\n",
        "    topLevel = (len(a.data)-1)+(len(b.data)-1)\n",
        "    maxLevel = _getMaxLevel(maxLevel)\n",
        "    if maxLevel is None or maxLevel>topLevel:\n",
        "        maxLevel = topLevel\n",
        "    out=[dict() for i in range(maxLevel+1)]\n",
        "    for level in range(0,maxLevel+1):\n",
        "        for blevel in range(0,min(level+1,len(b.data))):\n",
        "            alevel=level-blevel\n",
        "            if alevel >= len(a.data) or a.data[alevel] is None or b.data[blevel] is None:\n",
        "                continue\n",
        "            if alevel ==0:\n",
        "                continue\n",
        "            source=(0,)*(alevel-1) + (1,)*blevel\n",
        "            for l1,l2 in a.data[alevel].items():\n",
        "                for r1,r2 in b.data[blevel].items():\n",
        "                    prod=l2*r2\n",
        "                    out_=np.zeros(level,dtype=\"int32\")\n",
        "                    if level==1:#so l1 is a single letter\n",
        "                        _increment_value_in_dict_to_coeff(out[1],l1,prod)\n",
        "                    else:\n",
        "                        for mask in multiset_permutations(source):\n",
        "                            mask=np.array([0]+mask)\n",
        "                            np.place(out_,1-mask,l1.letters)\n",
        "                            np.place(out_,mask,r1.letters)\n",
        "                            w = Word(out_)\n",
        "                            _increment_value_in_dict_to_coeff(out[level],w,prod)\n",
        "    return Elt(out)\n",
        "\n",
        "def _allValuesFromElt(a):\n",
        "    assert isinstance(a,Elt), a\n",
        "    return tuple(itertools.chain.from_iterable(j.items() for j in a.data))\n",
        "\n",
        "def tensorProduct(*args):\n",
        "    \"\"\"construct an EltElt as a sequence of Elts and EltElts tensored together.\n",
        "    This is the tensor product of Elts (and EltElts), returning an EltElt.\n",
        "    It is the _external_ tensor product in tensor space\"\"\"\n",
        "    assert 0<len(args)\n",
        "    for a in args:\n",
        "        assert isinstance(a,(Elt,EltElt)), a\n",
        "    n_out = sum(1 if isinstance(a,Elt) else a.n for a in args)\n",
        "    out=dict()\n",
        "    vals=[[((i,),j) for i,j in _allValuesFromElt(a)] if isinstance(a,Elt) else a.data.items() for a in args]\n",
        "    for p in itertools.product(*vals):\n",
        "        k = functools.reduce(operator.concat,(i for i,j in p))\n",
        "        v = functools.reduce(operator.mul,(j for i,j in p))\n",
        "        _increment_value_in_dict_to_coeff(out,k,v)\n",
        "    return EltElt(out,n_out)\n",
        "\n",
        "def tensorProductFunctions(*args, **kwargs):\n",
        "    \"\"\"if f,g,h takes Elts and returns Elts or EltElts then\n",
        "    tensorProductFunctions(f,g,h) is the function f\\otimes g\\otimes h.\n",
        "    If some of f,g or h return EltElt with n>1, then provide a named argument n as the tensor exponent\n",
        "    we use to return in the case of zero input.\n",
        "    If you are using python 3 you should think of this function's signature as\n",
        "          \"def tensorProductFunctions(*args, n=None):\"\n",
        "    \"\"\"\n",
        "    assert 0<len(args)\n",
        "    if \"n\" in kwargs:\n",
        "        n=kwargs[\"n\"]\n",
        "    else:\n",
        "        n=len(args)\n",
        "    def loc_tensorProductFunctions(a):\n",
        "        assert isinstance(a,EltElt),a\n",
        "        assert len(args)==a.n\n",
        "        out=None\n",
        "        for k,v in a.data.items():\n",
        "            val=tensorProduct(*[i(word2Elt(j)) for i,j in zip(args,k)])*v\n",
        "            if out is None:\n",
        "                out = val\n",
        "            else:\n",
        "                out = out + val\n",
        "        if out is None:\n",
        "            return EltElt(dict(),n)\n",
        "        return out\n",
        "    return loc_tensorProductFunctions\n",
        "\n",
        "def concatenationProductEltElt(a,b):\n",
        "    assert isinstance(a,EltElt) and isinstance(b,EltElt), (a,b)\n",
        "    assert a.n == b.n\n",
        "    out=dict()\n",
        "    for k1,v1 in a.data.items():\n",
        "        for k2,v2 in b.data.items():\n",
        "            k=tuple(concatenate(i,j) for i,j in zip(k1,k2))\n",
        "            _increment_value_in_dict_to_coeff(out,k,v1*v2)\n",
        "    return EltElt(out,a.n)\n",
        "\n",
        "def shuffleConcatProduct(a,b,maxLevel=None):\n",
        "    \"\"\"The operation on two (Elt tensor Elt)s which is shuffle on left and\n",
        "    concatenation on right.\n",
        "    This is the product for the algebra {\\mathcal A} described on page 29.\n",
        "    The maxLevel argument is is just the maximum length of the first component.\n",
        "    In many cases, you know everything is a combination of (w1,w2) where\n",
        "    w1 and w2 are anagrams or at least have the same length, so this simple\n",
        "    maxLevel control is enough to control the runtime of this function.\"\"\"\n",
        "    assert isinstance(a,EltElt)\n",
        "    assert isinstance(b,EltElt)\n",
        "    assert a.n==2\n",
        "    assert b.n==2\n",
        "    maxLevel = _getMaxLevel(maxLevel)\n",
        "    o={}\n",
        "    for (k11,k12),v1 in a.data.items():\n",
        "        lenk11=len(k11.letters)\n",
        "        for (k21,k22),v2 in b.data.items():\n",
        "            if maxLevel is not None and len(k21.letters)+lenk11>maxLevel:\n",
        "               continue\n",
        "            v1v2=v1*v2\n",
        "            k2=concatenate(k12,k22)\n",
        "            sh=shuffleProduct(word2Elt(k11),word2Elt(k21))\n",
        "            for k,v in _allValuesFromElt(sh):\n",
        "                _increment_value_in_dict_to_coeff(o,(k,k2),v1v2*v)\n",
        "    return EltElt(o,2)\n",
        "\n",
        "def sum_word_tensor_word(d,m):\n",
        "    \"\"\"The sum of (w tensor w) for all words on d letters up to length m.\n",
        "    p30. Occurs in some identities.\"\"\"\n",
        "    o={}\n",
        "    for w in wordIter(d,m):\n",
        "        ww=Word(w)\n",
        "        o[(ww,ww)]=1\n",
        "    return EltElt(o,2)\n",
        "\n",
        "def sum_word_tensor_f_word(f,d,m):\n",
        "    \"\"\"The sum of (w tensor f(w)) for all words on d letters up to length m.\n",
        "    p30.\"\"\"\n",
        "    o={}\n",
        "    for w in wordIter(d,m):\n",
        "        ww=Word(w)\n",
        "        fww=f(word2Elt(ww))\n",
        "        for lev in fww.data:\n",
        "            for k,v in lev.items():\n",
        "                _increment_value_in_dict_to_coeff(o,(ww,k),v)\n",
        "    return EltElt(o,2)\n",
        "\n",
        "def swap_EltElt(a):\n",
        "    \"\"\"swap/transpose an EltElt representing (Elt tensor Elt)\"\"\"\n",
        "    assert isinstance(a,EltElt)\n",
        "    assert a.n == 2\n",
        "    o = {(k2,k1):v for (k1,k2),v in a.data.items()}\n",
        "    return EltElt(o,2)\n",
        "\n",
        "def dot_EltElt(a,b):\n",
        "    \"\"\"The dot product of two EltElts in the word basis\"\"\"\n",
        "    assert isinstance(a,EltElt) and isinstance(b,EltElt), (a,b)\n",
        "    assert a.n == b.n\n",
        "    out=zero_coefficient()\n",
        "    for k,v1 in a.data.items():\n",
        "        if k in b.data:\n",
        "            out += v1 * b.data[k]\n",
        "    return out\n",
        "\n",
        "def distance_EltElt(a,b):\n",
        "    \"\"\"The distance between the EltElts a and b in the word basis\"\"\"\n",
        "    assert isinstance(a,EltElt) and isinstance(b,EltElt), (a,b)\n",
        "    assert a.n==b.n\n",
        "    d=a-b\n",
        "    return math.sqrt(dot_EltElt(d,d))\n",
        "\n",
        "\n",
        "def log1p(a,maxLevel=None,useRational=None):\n",
        "    \"\"\"returns the tensor logarithm of (1+a) where a is an Elt with nothing in level 0.\n",
        "    if maxLevel is not given, only go up to the maximum level already in a\n",
        "     - there is no other way to pick a maximum level\n",
        "    This follows the pattern of iisignature's logTensorHorner\n",
        "    log(1+x) = x(1-x(1/2-x(1/3-x(1/4-...))))\n",
        "             = x-x(x/2-x(x/3-x(x/4-...)))\n",
        "    When inside p brackets, we only need the first m-p levels to be calculated,\n",
        "    because when multiplying a tensor t by x (which has 0 in the zeroth level)\n",
        "    level k of t only affects level k+1 and above of xt.\n",
        "    \"\"\"\n",
        "    assert isinstance(a,Elt), a\n",
        "    assert iszero_coefficient(get_coefficient(a,emptyWord)), a\n",
        "    maxLevel = _getMaxLevel(maxLevel)\n",
        "    if maxLevel is None:\n",
        "        maxLevel = len(a.data)-1\n",
        "    assert type(maxLevel) is int, maxLevel\n",
        "    s=t=zeroElt\n",
        "    for depth in range(maxLevel,0,-1):\n",
        "        constant = reciprocate_integer(depth, useRational)\n",
        "        t=concatenationProduct(a,s,1+maxLevel-depth)\n",
        "        if depth>1:\n",
        "            s=a*constant-t\n",
        "    return a-t\n",
        "\n",
        "def log(a,maxLevel=None,useRational=None):\n",
        "    \"\"\"tensor logarithm of a where a is an Elt with 1 in level 0\"\"\"\n",
        "    #TODO: Can generalise to level 0 being an arbitrary nonzero number,\n",
        "    #by dividing out the constant term, running this, and adding on\n",
        "    #math.log of the original constant\n",
        "    assert isinstance(a,Elt), a\n",
        "    assert isunit_coefficient(get_coefficient(a,emptyWord)), a\n",
        "    d=a.data[:]#Shallow copy, but ok, we won't return it\n",
        "    d[0]={emptyWord:zero_coefficient()}\n",
        "    return log1p(Elt(d), maxLevel,useRational)\n",
        "\n",
        "#exp(x)=1+x(1+x/2(1+x/3(...\n",
        "#=1+x+x/2(x+x/3(x+...))\n",
        "#exp can be defined even if a has a nonzero constant term,\n",
        "#by multiplying the answer by math.exp(the constant term)\n",
        "#- this agrees, of course, with the limit\n",
        "#of the power series.\n",
        "def exp(a,maxLevel=None,useRational=None):\n",
        "    \"\"\"tensor exponential of the Elt a.\n",
        "    You almost always need to specify a maxLevel here\"\"\"\n",
        "    assert isinstance(a,Elt), a\n",
        "    assert iszero_coefficient(get_coefficient(a,emptyWord)), a\n",
        "    maxLevel = _getMaxLevel(maxLevel)\n",
        "    if maxLevel is None:\n",
        "        maxLevel = len(a.data)-1\n",
        "    assert type(maxLevel) is int, maxLevel\n",
        "    s=zeroElt\n",
        "    for depth in range(maxLevel,0,-1):\n",
        "        constant = reciprocate_integer(1+depth, useRational)\n",
        "        t=concatenationProduct(a*constant,s,1+maxLevel-depth)\n",
        "        s=a+t\n",
        "    d=[None] if s is zeroElt else s.data\n",
        "    d[0]={emptyWord:unit_coefficient()}\n",
        "    return Elt(d)\n",
        "\n",
        "def log1p_shuffleConcat(a,maxLevel=None):\n",
        "    \"\"\"returns the tensor logarithm of (1+a) in the algebra {\\mathcal A}\n",
        "    if maxLevel is not given, only go up to the maximum level already in a\n",
        "     - there is no other way to pick a maximum level.\n",
        "    \"\"\"\n",
        "    assert isinstance(a,EltElt)\n",
        "    assert a.n==2\n",
        "    e_e=(emptyWord,emptyWord)\n",
        "    assert iszero_coefficient(a.data.get(e_e,0)), a\n",
        "    maxLevel = _getMaxLevel(maxLevel)\n",
        "    assert maxLevel is not None\n",
        "    assert type(maxLevel) is int, maxLevel\n",
        "    s=t=EltElt({},2)\n",
        "    for depth in range(maxLevel,0,-1):\n",
        "        constant = reciprocate_integer(depth)\n",
        "        t=shuffleConcatProduct(a,s,1+maxLevel-depth)\n",
        "        if depth>1:\n",
        "            s=a*constant-t\n",
        "    return a-t\n",
        "\n",
        "def exp_shuffleConcat(a, maxLevel=None):\n",
        "    \"\"\"exponential in the algebra {\\mathcal A}\n",
        "    (which is EltElts with n=2 with shuffleConcatProduct).\n",
        "    used e.g. in A Hopf-Algebraic Formula for Compositions of Noncommuting Flows\n",
        "    (Eric Gehrig and Matthias Kawski).\n",
        "\n",
        "    Note the meaning of the maxLevel argument, which is useful.\n",
        "    We only care about getting keys (k1,k2) correct if k1 and k2\n",
        "    have lengths maxLevel or less.\n",
        "    If you knew all keys in a were longer than 1 letter then\n",
        "    you don't need to run the calculation to as much depth as we do.\"\"\"\n",
        "    assert isinstance(a,EltElt)\n",
        "    assert a.n==2\n",
        "    e_e=(emptyWord,emptyWord)\n",
        "    assert iszero_coefficient(a.data.get(e_e,0)), a\n",
        "    maxLevel = _getMaxLevel(maxLevel)\n",
        "    if maxLevel is None:\n",
        "        maxLevel = a.getdeg()/2 #sensible guess\n",
        "\n",
        "    s=EltElt({},2)\n",
        "    for depth in range(maxLevel,0,-1):\n",
        "        constant = reciprocate_integer(1+depth)\n",
        "        t=shuffleConcatProduct(a*constant,s,1+maxLevel-depth)\n",
        "        s=a+t\n",
        "    return s + EltElt({e_e:unit_coefficient()},2)\n",
        "\n",
        "#This function was previously called 'id', which clashed with a python builtin\n",
        "def id_Elt(a):\n",
        "    \"\"\"The identity on Elts, id\"\"\"\n",
        "    assert isinstance(a,Elt), a\n",
        "    return a\n",
        "\n",
        "def I(a):\n",
        "    \"\"\"returns a with constant term removed\"\"\"\n",
        "    assert isinstance(a,Elt), a\n",
        "    out = a.data[:]\n",
        "    if len(out)>0:\n",
        "        out[0]=dict()\n",
        "    return Elt(out)\n",
        "\n",
        "def alpha(a):\n",
        "    \"\"\"The antipode.\n",
        "    E.g. if X is the truncated signature of a path, then alpha(X) is the one for the reversed path.\"\"\"\n",
        "    assert isinstance(a,Elt), a\n",
        "    out=[{Word(k.letters[::-1]):((-1)**level)*v\n",
        "          for k,v in x.items()}\n",
        "           for level, x in enumerate(a.data)]\n",
        "    return Elt(out)\n",
        "\n",
        "def reverseAllWords(a):\n",
        "    \"\"\"returns a version of the Elt a with all words reversed\"\"\"\n",
        "    assert isinstance(a,Elt), a\n",
        "    out=[{Word(k.letters[::-1]):v\n",
        "          for k,v in x.items()}\n",
        "           for level, x in enumerate(a.data)]\n",
        "    return Elt(out)\n",
        "\n",
        "def lieProduct(a,b, maxLevel=None):\n",
        "    \"\"\"The Lie product of Elts a and b\"\"\"\n",
        "    assert isinstance(a,Elt) and isinstance(b,Elt), (a,b)\n",
        "    return concatenationProduct(a,b,maxLevel)-concatenationProduct(b,a,maxLevel)\n",
        "\n",
        "def deltaOfLetter(letter,p):\n",
        "    w=Word((letter,))\n",
        "    o=unit_coefficient()\n",
        "    tuples=[(emptyWord,)*i+(w,)+(emptyWord,)*(p-1-i) for i in range(p)]\n",
        "    return EltElt({i:o for i in tuples},p)\n",
        "\n",
        "def delta(a,p=2):#sh*, adjoint of sh\n",
        "    \"\"\"delta(x) is $\\delta(x)$. delta(x,p) is $\\delta_p(x)$\n",
        "       deshuffle coproduct: if w is a word, delta(w) is the sum of the pairs\n",
        "       of words (in both orders) of which w is a shuffle of the pair.\n",
        "       delta is thus clearly cocommutative\n",
        "       delta(ab)=delta(a)delta(b) so delta is an algebra morphism from\n",
        "       Elt to EltElt with each having concatenation\"\"\"\n",
        "    assert isinstance(a,Elt), a\n",
        "    assert isinstance(p,int), p\n",
        "    out=dict()\n",
        "    c = get_coefficient(a,emptyWord)\n",
        "    if not iszero_coefficient(c):\n",
        "        out[(emptyWord,)*p]=c\n",
        "    for i in range(1,len(a.data)):\n",
        "        for k,v in a.data[i].items():\n",
        "            x=[deltaOfLetter(j,p) for j in k.letters]\n",
        "            prod=functools.reduce(concatenationProductEltElt,x)\n",
        "            for k2,v2 in prod.data.items():\n",
        "                _increment_value_in_dict_to_coeff(out,k2,v2*v)\n",
        "    return EltElt(out,p)\n",
        "\n",
        "def deltabar(a):\n",
        "    assert isinstance(a,Elt), a\n",
        "    d=delta(a)\n",
        "    out={(i,Word(j.letters[::-1])):v*((-1)**len(j.letters)) for (i,j),v in d.data.items()}\n",
        "    return EltElt(out,2)\n",
        "\n",
        "def deltadash(a,p=2): #aka conc*, p27, deconcatenation coproduct\n",
        "    \"\"\"deltadash(x) is $\\delta'(x)$. delta(x,p) is $\\delta'_p(x)$\"\"\"\n",
        "    assert isinstance(a,Elt), a\n",
        "    assert isinstance(p,int), p\n",
        "    \n",
        "    #copied from sympy kbins but allow empty bins\n",
        "    def partition(lista, bins):\n",
        "        #  EnricoGiampieri's partition generator from\n",
        "        #  http://stackoverflow.com/questions/13131491/\n",
        "        #  partition-n-items-into-k-bins-in-python-lazily\n",
        "        if bins == 1:\n",
        "            yield [lista]\n",
        "        elif bins > 1:\n",
        "            for i in range(0, len(lista)+1):\n",
        "                for part in partition(lista[i:], bins - 1):\n",
        "                    if len([lista[:i]] + part) == bins:\n",
        "                        yield [lista[:i]] + part\n",
        "    out=dict()\n",
        "    for x in a.data:\n",
        "        for k,v in x.items():\n",
        "            for i in partition(k.letters,p):\n",
        "                k2=tuple(Word(j) for j in i)\n",
        "                _increment_value_in_dict_to_coeff(out,k2,v)\n",
        "    return EltElt(out,p)\n",
        "    \n",
        "def ad(a):\n",
        "    assert isinstance(a,Elt), a\n",
        "    return lambda b: lieProduct(a,b)\n",
        "\n",
        "def r(a):\n",
        "    \"\"\"Right Lie-bracketing function, extended linearly to Elts.\n",
        "    e.g. 123 -> [1,[2,3]]\n",
        "    This is also known as the Dynkin map\"\"\"\n",
        "    assert isinstance(a,Elt), a\n",
        "    out = [dict() for i in a.data]\n",
        "    for i,x in enumerate(a.data):\n",
        "        if i>0:\n",
        "            for k,v in x.items():\n",
        "                rr = [letter2Elt(j) for j in reversed(k.letters)]\n",
        "                f = functools.reduce(lambda y,z:lieProduct(z,y),rr)\n",
        "                for k2,v2 in f.data[i].items():#We only need to look in level i\n",
        "                    _increment_value_in_dict_to_coeff(out[i],k2,v2*v)\n",
        "    return Elt(out)\n",
        "\n",
        "def l(a):\n",
        "    \"\"\"Left Lie-bracketing function, extended linearly to Elts.\n",
        "    e.g. 123 -> [[1,2],3]\n",
        "    page 36.\"\"\"\n",
        "    assert isinstance(a,Elt), a\n",
        "    out = [dict() for i in a.data]\n",
        "    for i,x in enumerate(a.data):\n",
        "        if i>0:\n",
        "            for k,v in x.items():\n",
        "                rr = [letter2Elt(j) for j in k.letters]\n",
        "                f = functools.reduce(lieProduct,rr)\n",
        "                for k2,v2 in f.data[i].items():#We only need to look in level i\n",
        "                    _increment_value_in_dict_to_coeff(out[i],k2,v2*v)\n",
        "    return Elt(out)\n",
        "\n",
        "def Ad(a):\n",
        "    assert isinstance(a,Elt), a\n",
        "    def loc_Ad(b):\n",
        "        assert isinstance(b,Elt), b\n",
        "        out=zeroElt\n",
        "        for x in a.data:\n",
        "            for k,v in x.items():\n",
        "                y=b\n",
        "                for j in reversed(k.letters):\n",
        "                   y=lieProduct(letter2Elt(j),y)\n",
        "                out = out + v*y\n",
        "        return out\n",
        "    return loc_Ad\n",
        "\n",
        "#test (?) Ad(exp(x))(y)=exp(ad(x)(y)) ?for Lie elts x and y\n",
        "#Ad is the derivative of conjugation?\n",
        "\n",
        "def D(a):\n",
        "    assert isinstance(a,Elt), a\n",
        "    out=[{k:level*v\n",
        "          for k,v in x.items()}\n",
        "           for level, x in enumerate(a.data)]\n",
        "    out[0]=dict()\n",
        "    return Elt(out)\n",
        "\n",
        "def dilate(a, factor):\n",
        "    \"\"\"multiply each level m by factor**m.\n",
        "    This is an automorphism of the grouplike elements.\n",
        "    In terms of signatures, corresponds to an enlargement/homothety/scaling\n",
        "    of the underlying path which is uniform/isotropic.\n",
        "    Commutes with lots of things - e.g. log.\"\"\"\n",
        "    assert isinstance(a,Elt), a\n",
        "    multdict = lambda x,f: {k:f*v for k,v in x.items()}\n",
        "    out=[multdict(x,factor**level)\n",
        "            for level, x in enumerate(a.data)]\n",
        "    return Elt(out)\n",
        "\n",
        "def D_inv(a):\n",
        "    \"\"\"The inverse of (D restricted to elements which are 0 in level 0).\n",
        "    possibly not in Reutenauer.\"\"\"\n",
        "    assert isinstance(a,Elt), a\n",
        "    assert iszero_coefficient(get_coefficient(a,emptyWord)), a\n",
        "    out=[{k:v*(0 if level==0 else reciprocate_integer(level))\n",
        "          for k,v in x.items()}\n",
        "           for level, x in enumerate(a.data)]\n",
        "    return Elt(out)\n",
        "\n",
        "def conc(a):\n",
        "    \"\"\"This is both conc and conc_p, as we don't assert a.n==2 .\n",
        "    If you think of Elts as the tensor space of a vector space V,\n",
        "    then this is the obvious morphism from external-tensor-product\n",
        "    (say \\boxtimes) powers (i.e. EltElt) to internal-tensor-product\n",
        "    (i.e. concatenation product, say \\otimes) powers (i.e. Elt)\n",
        "    which takes a\\boxtimes b to a\\otimes b.\n",
        "    \"\"\"\n",
        "    assert isinstance(a,EltElt), a\n",
        "    out=[dict() for i in range(a.get_deg()+1)]\n",
        "    for k,v in a.data.items():\n",
        "        w=functools.reduce(concatenate,k)\n",
        "        _increment_value_in_dict_to_coeff(out[len(w.letters)],w,v)\n",
        "    return Elt(out)\n",
        "\n",
        "def sh(a):\n",
        "    assert isinstance(a,EltElt), a\n",
        "    assert a.n==2, a\n",
        "    out=[dict() for i in range(a.get_deg()+1)]\n",
        "    for (x,y),v in a.data.items():\n",
        "        source=(0,)*len(x.letters)+(1,)*len(y.letters)\n",
        "        level=len(source)\n",
        "        out_=np.zeros(level,dtype=\"int32\")\n",
        "        if(level==0):\n",
        "            _increment_value_in_dict_to_coeff(out[level],emptyWord,v)\n",
        "        else:\n",
        "            for mask in multiset_permutations(source):\n",
        "                mask=np.array(mask)\n",
        "                np.place(out_,1-mask,x.letters)\n",
        "                np.place(out_,mask,y.letters)\n",
        "                w = Word(out_)\n",
        "                _increment_value_in_dict_to_coeff(out[level],w,v)\n",
        "    return Elt(out)\n",
        "\n",
        "def sh_p(a):\n",
        "    \"\"\"This is the generic sh_p, we don't need p as an input. sh_p(a)==sh(a) if a.n==2\"\"\"\n",
        "    assert isinstance(a,EltElt), a\n",
        "    out=zeroElt\n",
        "    for x,v in a.data.items():\n",
        "        y=functools.reduce(shuffleProduct,[word2Elt(i) for i in x])\n",
        "        out = out + y*v\n",
        "    return out\n",
        "\n",
        "def star(f,g):\n",
        "    \"\"\"convolution\"\"\"\n",
        "    t=tensorProductFunctions(f,g)\n",
        "    def loc_star(a):\n",
        "        assert isinstance(a,Elt), a\n",
        "        return conc(t(delta(a)))\n",
        "    return loc_star\n",
        "\n",
        "def stardash(f,g):\n",
        "    t=tensorProductFunctions(f,g)\n",
        "    def loc_stardash(a):\n",
        "        assert isinstance(a,Elt), a\n",
        "        return sh(t(deltadash(a)))\n",
        "    return loc_stardash\n",
        "\n",
        "def lambda_(a):\n",
        "    assert isinstance(a,EltElt), a\n",
        "    assert a.n==2,a\n",
        "    out=[dict() for i in range(a.get_deg()+1)]\n",
        "    for k,v in a.data.items():\n",
        "        w=Word(k[0].letters[::-1]+k[1].letters)\n",
        "        _increment_value_in_dict_to_coeff(out[len(w.letters)],w,v*len(k[0].letters))\n",
        "    return Elt(out)\n",
        "\n",
        "def mu(a):\n",
        "    assert isinstance(a,EltElt), a\n",
        "    assert a.n==2,a\n",
        "    def loc_mu(b):\n",
        "        assert isinstance(b,Elt), b\n",
        "        out=zeroElt\n",
        "        for (x,y),v in a.data.items():\n",
        "            out = out + concatenationProductMany([word2Elt(x),b,word2Elt(y)])*v\n",
        "        return out\n",
        "    return loc_mu\n",
        "\n",
        "def rhoOfWord(letters): #p32\n",
        "    l=len(letters)\n",
        "    if l==0:\n",
        "        return zeroElt\n",
        "    if l==1:\n",
        "        return letter2Elt(letters[0])\n",
        "    return (concatenationProduct(letter2Elt(letters[ 0]),rhoOfWord(letters[1:]))-\n",
        "                          concatenationProduct(letter2Elt(letters[-1]),rhoOfWord(letters[:-1])))\n",
        "\n",
        "def rho(a):\n",
        "    assert isinstance(a,Elt), a\n",
        "    out=[dict() for i in a.data]\n",
        "    for i,x in enumerate(a.data):\n",
        "        for k,v in x.items():\n",
        "            f = rhoOfWord(k.letters)\n",
        "            for k2,v2 in f.data[i].items():#We only need to look in one level of f\n",
        "                _increment_value_in_dict_to_coeff(out[i],k2,v2*v)\n",
        "    return Elt(out)\n",
        "\n",
        "#note: This definition of pi1 is following the remark just before eqn 3.2.4.\n",
        "#Although this looks inefficient, the direct calculation  of pi1 using equation 3.2.3\n",
        "#looks bad too, as we need to decompose words into all the shuffles (i.e. partitions) that make them.\n",
        "#pi1adjoint I do do directly though, because the decomposition into concatenations feels easier\n",
        "def pi1(a):\n",
        "    \"\"\"the unique linear map on Elts s.t. log(x)=pi1(x) for any grouplike x\"\"\"\n",
        "    assert isinstance(a,Elt), a\n",
        "    #p58: pi_1=log(id_Elt)=log(epsilon+I)=log1p(I) [because epsilon is the unit in the algebra of End(K<A>)]\n",
        "    maxlevel=len(a.data)-1\n",
        "    out=zeroElt\n",
        "    fn=None\n",
        "    for i in range(1,maxlevel+1):\n",
        "        fn=I if i==1 else star(I,fn)\n",
        "        out+=fn(a)*(reciprocate_integer(i)*(-1)**(i-1))\n",
        "    return out\n",
        "\n",
        "def pi1adjointOfWord(word):\n",
        "    assert isinstance(word,Word),word\n",
        "    l=len(word.letters)\n",
        "    if l==0:\n",
        "        return zeroElt\n",
        "    if l==1:\n",
        "        return word2Elt(word)\n",
        "    out=zeroElt\n",
        "    lets = [letter2Elt(i) for i in word.letters]\n",
        "    for k in range(1,l+1):\n",
        "        constant = (-1)**(k-1)*reciprocate_integer(k)\n",
        "        for u in kbins(lets,k):\n",
        "            v=[concatenationProductMany(i) for i in u]\n",
        "            out += constant * shuffleProductMany(v)\n",
        "    return out\n",
        "\n",
        "\n",
        "#Previously called pi1star\n",
        "#useful for the following reason.\n",
        "#if L is a Lie element and G is grouplike, then\n",
        "#(L,log(G)) = (L,pi1(G)) = (pi1adjoint(L),G)\n",
        "#and L can of course be written in the pbw basis as a linear combination of P(w) for hall words w\n",
        "#which is how the log signature is written.\n",
        "#So the linear function on signatures which returns element w of the log signature is\n",
        "#f(X) = dotprod(pistar(S(w)),X)\n",
        "def pi1adjoint(a):\n",
        "    \"\"\"adjoint of pi1\n",
        "    This is what is known as $\\pi_1^*$ in Section 6.2 (p129) of Reutenauer.\n",
        "    It is what Eric Gehrig and Matthias Kawski call $\\pi_1'$ in their\n",
        "    'A Hopf-Algebraic Formula for Compositions of Noncommuting Flows' \"\"\"\n",
        "    assert isinstance(a,Elt), a\n",
        "    out=[dict() for i in a.data]\n",
        "    for i,x in enumerate(a.data):\n",
        "        for k,v in x.items():\n",
        "            f = pi1adjointOfWord(k)\n",
        "            for k2,v2 in f.data[i].items():#We only need to look in one level of f\n",
        "                _increment_value_in_dict_to_coeff(out[i],k2,v2*v)\n",
        "    return Elt(out)    \n",
        "\n",
        "def pi(a,n):\n",
        "    \"\"\"\\pi_n(a)\n",
        "    NB: This is not the function for projecting to the nth level, or up to the nth level, \n",
        "    which some authors call \\pi_n. For that, use the restrictedToLevel or truncatedToLevel \n",
        "    member functions of Elt.\"\"\"\n",
        "    #This implementation is simple but slow\n",
        "    #equation 3.2.6\n",
        "    assert isinstance(a,Elt), a\n",
        "    if(n==0):\n",
        "        return epsilon(a)\n",
        "    b=delta(a,n)\n",
        "    c=tensorProductFunctions(*([pi1]*n))(b)\n",
        "    d=conc(c)\n",
        "    return d*reciprocate_integer(math.factorial(n))\n",
        "\n",
        "###BEGIN HALL BASIS STUFF\n",
        "\n",
        "def foliage_iter(x):\n",
        "    if type(x) is int:\n",
        "        yield x\n",
        "        return\n",
        "    assert type(x) is tuple, x\n",
        "    for i in x:\n",
        "        for j in foliage_iter(i):\n",
        "            yield j\n",
        "\n",
        "def foliageFromTree(tup):\n",
        "    return \"\".join(str(i) for i in foliage_iter(tup))\n",
        "\n",
        "\n",
        "def printTreeAsLieBrackets(tup):\n",
        "    if len(tup)==1:\n",
        "        return str(tup[0])\n",
        "    return \"[\"+printTreeAsLieBrackets(tup[0])+\",\"+printTreeAsLieBrackets(tup[1])+\"]\"\n",
        "\n",
        "def count_identical_right_factors(tree):\n",
        "    \"\"\"\n",
        "    Given a tree, we can ask how many times it has its right factor.\n",
        "    Let da(x) be the function mapping y to [y,x] (This is the ad applied the other way round, or minused).\n",
        "    Then count_identical_right_factors(tree) is the maximum n such that there are x and y\n",
        "    such that da(x)^n (y)==tree.\n",
        "    E.g. (((1,),(4,)),(4,)) maps to 2.\n",
        "    \"\"\"\n",
        "    if not isinstance(tree, tuple) or len(tree)==1:\n",
        "        return 1\n",
        "    count = 1\n",
        "    rhs = tree[1]\n",
        "    lhs = tree[0]\n",
        "    while len(lhs)==2 and lhs[1]==rhs:\n",
        "        count +=1\n",
        "        lhs = lhs[0]\n",
        "    return count\n",
        "\n",
        "def count_identical_left_factors(tree):\n",
        "    \n",
        "    if not isinstance(tree, tuple) or len(tree)==1:\n",
        "        return 1\n",
        "    count = 1\n",
        "    rhs = tree[1]\n",
        "    lhs = tree[0]\n",
        "    while len(rhs)==2 and rhs[1]==lhs:\n",
        "        count +=1\n",
        "        rhs = rhs[0]\n",
        "    return count\n",
        "\n",
        "def lessExpressionLyndon(a,b):\n",
        "    return tuple(foliage_iter(a))<tuple(foliage_iter(b))\n",
        "\n",
        "def lessExpressionNyldon(a,b):\n",
        "    return tuple(foliage_iter(a))>tuple(foliage_iter(b))\n",
        "\n",
        "#this is the other way around from coropa\n",
        "def lessExpressionStandardHall(a,b):\n",
        "    ll=len(tuple(foliage_iter(a)))\n",
        "    lr=len(tuple(foliage_iter(b)))\n",
        "    if ll!=lr:\n",
        "        return lr<ll\n",
        "    if 1==ll:\n",
        "        return a<b\n",
        "    if a[0]==b[0]:\n",
        "         return lessExpressionStandardHall(a[1],b[1])\n",
        "    return lessExpressionStandardHall(a[0],b[0])\n",
        "\n",
        "\n",
        "def nOfDerivedBasisElement(e):\n",
        "    \"\"\"If e is an element of a Hall basis 'compatible with the derived series',\n",
        "       then it must be a member of some H_n. See section 5.3. Return that n.\n",
        "    \"\"\"\n",
        "    if len(e)==1:\n",
        "        return 0\n",
        "    return 1+nOfDerivedBasisElement(e[1])\n",
        "\n",
        "#given an order L on trees, DerivedLess(L) is the order on trees\n",
        "#corresponding to the Hall basis described in section 5.3\n",
        "#which keeps H_0>H_1>H_2... and which uses L on trees within each H_n\n",
        "#This determines a Hall basis which is then compatible with the derived\n",
        "#series.\n",
        "#Having the order defined on all trees determines the HallBasis,\n",
        "#so we don't need to code\n",
        "#the algorithm - e.g. eqn 5.3.2 - separately if we want the basis,\n",
        "#we can just call the HallBasis constructor with this order.\n",
        "class DerivedLess:\n",
        "    def __init__(self, L):\n",
        "        self.L = L\n",
        "    def __call__(self, a, b):\n",
        "        aa = nOfDerivedBasisElement(a)\n",
        "        bb = nOfDerivedBasisElement(b)\n",
        "        if aa==bb:\n",
        "            return self.L(a,b)\n",
        "        return aa>bb\n",
        "\n",
        "class KeyFromLess:\n",
        "    \"\"\"Adapter for using a `less' function as a key in sort or sorted\"\"\"\n",
        "    def __init__(self, less):\n",
        "        self.less=less\n",
        "    @functools.total_ordering\n",
        "    class Key:\n",
        "        def __init__(self, less, tree):\n",
        "            self.tree=tree\n",
        "            self.less=less\n",
        "        def __eq__(self,o):\n",
        "            #often identity will be enough here\n",
        "            return o.tree==self.tree\n",
        "        def __lt__(self,o):\n",
        "            return self.less(self.tree,o.tree)\n",
        "    def __call__(self, tree):\n",
        "        return self.Key(self.less, tree)\n",
        "\n",
        "def basisElementToElt(b):\n",
        "    assert type(b) in (int, tuple)\n",
        "    if type(b) is int:\n",
        "        return letter2Elt(b)\n",
        "    if len(b)==1:\n",
        "        return letter2Elt(b[0])\n",
        "    return lieProduct(basisElementToElt(b[0]),basisElementToElt(b[1]))\n",
        "\n",
        "#A basis knows about its elements as tuples.\n",
        "#Note that data[m-1] is the basis elements (trees) of level m.\n",
        "class HallBasis:\n",
        "    def __init__(self, d, m, lessExpression=lessExpressionLyndon, sortLevels=True):\n",
        "        assert d>1\n",
        "        assert m>0\n",
        "        self.d=d\n",
        "        self.m=m\n",
        "        self.less=lessExpression\n",
        "        self.sortKey=KeyFromLess(lessExpression)\n",
        "\n",
        "        out=[[(i,) for i in range(1,d+1)]]\n",
        "        for mm in range(2,m+1):\n",
        "            out.append([])\n",
        "            for firstLev in range(1,mm):\n",
        "                for x in out[firstLev-1]:\n",
        "                    for y in out[mm-firstLev-1]:\n",
        "                        if lessExpression(x,y) and (firstLev==1 or not lessExpression(x[1],y)):\n",
        "                            out[-1].append((x,y))\n",
        "            if sortLevels:\n",
        "                out[-1].sort(key=self.sortKey)\n",
        "        self.data=out\n",
        "\n",
        "    #w must be str or tuple of ints\n",
        "    def findAsFoliageOfHallWord(self, w):\n",
        "        \"\"\"If the word w is a Hall word, return the corresponding Hall tree,\n",
        "        otherwise return None\"\"\"\n",
        "        assert type(w) in (tuple,str), w\n",
        "        assert 0<len(w)<=self.m\n",
        "        if type(w)==str:\n",
        "            w=tuple(int(i) for i in w)\n",
        "        for i in self.data[len(w)-1]:\n",
        "            if w == tuple(foliage_iter(i)):\n",
        "                return i\n",
        "        return None\n",
        "    #w must be str or tuple of ints\n",
        "    def factorIntoHallWords(self,w):\n",
        "        assert type(w) in (tuple,str), w\n",
        "        assert 0<len(w)<=self.m\n",
        "        if type(w)==str:\n",
        "            w=tuple(int(i) for i in w)\n",
        "        l=len(w)\n",
        "        if l==1:\n",
        "            assert 1<=w[0]<=self.d, str(w[0])+\" is not in my alphabet\"\n",
        "            return [w]\n",
        "        best=(w[-1],)\n",
        "        best_prefix_length=l-1\n",
        "        for prefix_length in range(0,l-1):\n",
        "            end=w[prefix_length:]\n",
        "            endH=self.findAsFoliageOfHallWord(end)\n",
        "            if endH is not None and self.less(endH,best):\n",
        "                best=endH\n",
        "                best_prefix_length=prefix_length\n",
        "        if best_prefix_length==0:\n",
        "            return [best]\n",
        "        return self.factorIntoHallWords(w[:best_prefix_length])+[best]\n",
        "\n",
        "    def foliageLookup(self,m):\n",
        "        \"\"\"return dict from foliage to hall word index in level m\"\"\"\n",
        "        assert 0<m<=self.m\n",
        "        out=dict()\n",
        "        for i,tree in enumerate(self.data[m-1]):\n",
        "            out[tuple(foliage_iter(tree))]=i\n",
        "        return out\n",
        "    \n",
        "    def indicesOfHallWords(self, m):\n",
        "        \"\"\"returns an array of length d**m where elements which are HallWords correspond to their index\n",
        "        and all other indices are -1\"\"\"\n",
        "        assert 0<m<=self.m\n",
        "        if m==1:\n",
        "            return np.arange(self.d)\n",
        "        d=self.foliageLookup(m)\n",
        "        out=[d.get(wd,-1) for wd in wordIter(self.d,m,topOnly=True,asNumbers=True)]\n",
        "        return np.array(out)\n",
        "\n",
        "    def indicesOfAnagramSet(self, counts):\n",
        "        \"\"\"return the indices (in the relevant level) of elements which have the homogeneity given by counts\"\"\"\n",
        "        counts = list(counts)\n",
        "        while len(counts)<self.d:\n",
        "            counts=counts+[0]\n",
        "        assert len(counts)==self.d\n",
        "        level = sum(counts)\n",
        "        assert 0<level <= self.m\n",
        "        o=[]\n",
        "        for i, tree in enumerate(self.data[level-1]):\n",
        "            counts_=list(counts)\n",
        "            for letter in foliage_iter(tree):\n",
        "                if counts_[letter-1]==0:\n",
        "                    break\n",
        "                counts_[letter-1]-=1\n",
        "            else:\n",
        "                o.append(i)\n",
        "        return o\n",
        "\n",
        "    def allElementsInOrder(self):\n",
        "        \"\"\"return list of all Hall trees sorted in ascending order according to the defining order\"\"\"\n",
        "        o=[i for dat in self.data for i in dat]\n",
        "        o.sort(key=self.sortKey)\n",
        "        return o\n",
        "\n",
        "def arbitraryLieEltSympy(basis, m=None, symbol='x'):\n",
        "    \"\"\"return an arbitrary Lie element with Sympy coefficients\"\"\"\n",
        "    assert isinstance(basis, HallBasis), basis\n",
        "    if m==None:\n",
        "        m=basis.m\n",
        "    assert m<=basis.m\n",
        "    assert 1<basis.d<10\n",
        "    out = zeroElt\n",
        "    for levelMinus1 in range(m):\n",
        "        for tree in basis.data[levelMinus1]:\n",
        "            name = foliageFromTree(tree)\n",
        "            coeff = sympy.var(symbol+\"_\"+name)\n",
        "            elt = basisElementToElt(tree)\n",
        "            out += elt*coeff\n",
        "    return out\n",
        "\n",
        "def arbitraryGrouplikeEltSympy(basis, m=None, symbol='x'):\n",
        "    \"\"\"return an arbitrary grouplike element with Sympy coefficients\"\"\"\n",
        "    l=arbitraryLieEltSympy(basis,m,symbol)\n",
        "    return exp(l)\n",
        "\n",
        "def P(w, basis):\n",
        "    assert isinstance(basis, HallBasis), basis\n",
        "    assert type(w) in (tuple,str), w\n",
        "    if 0==len(w):\n",
        "        return unitElt\n",
        "    assert 0<len(w)<=basis.m\n",
        "    a=basis.factorIntoHallWords(w)\n",
        "    out = functools.reduce(concatenationProduct,(basisElementToElt(i) for i in a))\n",
        "    return out\n",
        "\n",
        "def S(w, basis):\n",
        "    \"\"\"Dual PBW basis element, p108\"\"\"\n",
        "    assert isinstance(basis, HallBasis), basis\n",
        "    assert type(w) in (tuple,str), w\n",
        "    assert len(w)<=basis.m\n",
        "    if type(w)==str:\n",
        "        w=tuple(int(i) for i in w)\n",
        "    else:\n",
        "        for i in w:\n",
        "            assert isinstance(i,(int, str)), \"perhaps you supplied a tree not a word?\"\n",
        "    if len(w)==0:\n",
        "        return unitElt\n",
        "    a=basis.factorIntoHallWords(w)\n",
        "    if len(a)==1:\n",
        "        return concatenationProduct(letter2Elt(w[0]),S(w[1:],basis))\n",
        "    factor=1.0\n",
        "    out = unitElt\n",
        "    for i,j in itertools.groupby(a):\n",
        "        word=tuple(foliage_iter(i))\n",
        "        num=len(tuple(j))\n",
        "        factor *= math.factorial(num)\n",
        "        base = S(word,basis)\n",
        "        power = functools.reduce(shuffleProduct,(base for i in range(num)))\n",
        "        out = shuffleProduct(out,power)\n",
        "    out = out*reciprocate_integer(factor)\n",
        "    return out\n",
        "\n",
        "def wordToShuffleOfLogSigElts(w,basis):\n",
        "    \"\"\"If w's factorisation into hall words is h_1..h_n, return shuffle product of {pi1adjoint(S(h_i,basis))}.\n",
        "    This is possibly our idea.\"\"\"\n",
        "    assert isinstance(basis, HallBasis), basis\n",
        "    assert type(w) in (tuple,str), w\n",
        "    if 0==len(w):\n",
        "        return unitElt\n",
        "    assert 0<len(w)<=basis.m\n",
        "    a=basis.factorIntoHallWords(w)\n",
        "    #out = functools.reduce(shuffleProduct,(basisElementToElt(i) for i in a))\n",
        "    out = functools.reduce(shuffleProduct,(pi1adjoint(S(foliageFromTree(i),basis)) for i in a))\n",
        "    return out\n",
        "\n",
        "def Q(w, basis, ignoreFactor=False):#p128\n",
        "    \"\"\"Word w -> shuffle of its hall factors, with constant coefficients of repeats divided out\"\"\"\n",
        "    assert isinstance(basis, HallBasis), basis\n",
        "    assert type(w) in (tuple,str), w\n",
        "    assert len(w)<=basis.m\n",
        "    assert basis.less == lessExpressionLyndon\n",
        "    if type(w)==str:\n",
        "        w=tuple(int(i) for i in w)\n",
        "    if len(w)==0:\n",
        "        return unitElt\n",
        "    a=basis.factorIntoHallWords(w)\n",
        "    factor=1\n",
        "    out = unitElt\n",
        "    for i,j in itertools.groupby(a):\n",
        "        word=tuple(foliage_iter(i))\n",
        "        num=len(tuple(j))\n",
        "        factor *= math.factorial(num)\n",
        "        base = word2Elt(word)\n",
        "        power = functools.reduce(shuffleProduct,(base for i in range(num)))\n",
        "        out = shuffleProduct(out,power)\n",
        "    if not ignoreFactor:\n",
        "        out = out*reciprocate_integer(factor)\n",
        "    return out\n",
        "\n",
        "class TensorSpaceBasis:\n",
        "    \"\"\"A basis of tensor space up to level m on d letters, given by a function fn which maps words of\n",
        "    length mm to each basis element of level mm. Trivial example is fn=word2Elt, but other cases work too,\n",
        "    where we supply a hall basis too to fn. \n",
        "    Interesting cases are fn=P (the Poincare-Birkhoff-Witt basis) and fn=S (its dual).\"\"\"\n",
        "    def __init__(self, fn, basis=None, d=None, m=None, checkFn=True):\n",
        "        #would be nice to remove this assertion\n",
        "        #but it's easy to get the arguments of this ctor in the wrong order\n",
        "        if checkFn:\n",
        "            assert fn in (word2Elt, P, S, Q), fn\n",
        "        if basis is not None:\n",
        "            assert isinstance(basis, HallBasis), basis\n",
        "            if d is None:\n",
        "                d=basis.d\n",
        "            if m is None:\n",
        "                m=basis.m\n",
        "        assert d is not None\n",
        "        assert m is not None\n",
        "                \n",
        "        if fn==word2Elt:\n",
        "            self.fn=word2Elt\n",
        "        else:\n",
        "            assert isinstance(basis, HallBasis), basis\n",
        "            assert 0<m<=basis.m\n",
        "            assert 0<d<=basis.d\n",
        "            self.fn= lambda x:fn(x,basis)\n",
        "        self.d=d\n",
        "        self.m=m\n",
        "        if fn != word2Elt:\n",
        "            from itertools import product\n",
        "            alphabet=list(range(1,d+1))\n",
        "            o=[]\n",
        "            for r in range(m+1):\n",
        "                words = list(product(alphabet,repeat=r))\n",
        "                locdata=[]\n",
        "                for w in words:\n",
        "                    val=self.fn(w)\n",
        "                    a=[val.data[r].get(Word(w2),0) for w2 in words]\n",
        "                    locdata.append(a)\n",
        "                o.append(np.array(locdata,dtype=\"float64\"))\n",
        "            self.data=o\n",
        "        #print(self.data)\n",
        "\n",
        "    #Simple constructors\n",
        "    @staticmethod\n",
        "    def wordBasis(d,m=None):\n",
        "        if m is None and isinstance(d, HallBasis):\n",
        "            return TensorSpaceBasis(word2Elt, d=d.d, m=d.m)\n",
        "        return TensorSpaceBasis(word2Elt,d=d,m=m)\n",
        "    @staticmethod\n",
        "    def fromFunctionAndHallBasis(fn, hallBasis, m=None):\n",
        "        \"\"\"get a basis given a function on words which like P and S returns a basis element for each word.\"\"\"\n",
        "        return TensorSpaceBasis(fn,hallBasis,m=m,checkFn=False)\n",
        "\n",
        "    def generateWordsElts(self):\n",
        "        from itertools import product\n",
        "        alphabet=list(range(1,self.d+1))\n",
        "        for r in range(self.m+1):\n",
        "            words = list(product(alphabet,repeat=r))\n",
        "            for w in words:\n",
        "                val=self.fn(w)\n",
        "                yield \"\".join(str(i) for i in w),val\n",
        "        \n",
        "    def size(self):\n",
        "#        return sum(i.shape[0] for i in self.data)\n",
        "        return sum(self.d**r for r in range(1+self.m))\n",
        "    \n",
        "    def indexOfLevelStart(self, level):\n",
        "        return sum(self.d**r for r in range(level))\n",
        "        \n",
        "    def toElt(self,x,m=None):\n",
        "        \"\"\"return the Elt corresponding to a list of coefficients of our elements\"\"\"\n",
        "        \"\"\"if m is specified, x only contains level m, instead of all levels up to self.m\"\"\"\n",
        "        if m is None:\n",
        "            assert len(x)==self.size()\n",
        "        else:\n",
        "            assert m<=self.m\n",
        "            assert len(x)==self.d**m\n",
        "        out=zeroElt\n",
        "        it = iter(x)\n",
        "        alphabet=list(range(1,self.d+1))\n",
        "        if self.fn != word2Elt:\n",
        "            R = enumerate(self.data) if m is None else [(m,self.data[m])]\n",
        "            for r, mat in R:\n",
        "                y=np.zeros_like(mat[:,0])\n",
        "                for row in mat:\n",
        "                    y=y+next(it)*row\n",
        "                for i,j in zip(y,itertools.product(alphabet,repeat=r)):\n",
        "                    out +=i*word2Elt(j)\n",
        "        else:\n",
        "            if m is None:\n",
        "                o=[{Word(a):next(it) for a in itertools.product(alphabet,repeat=r)} for r in range(self.m+1)]\n",
        "            else:\n",
        "                o=[dict() for r in range(m)]\n",
        "                o.append({Word(a):next(it) for a in itertools.product(alphabet,repeat=m)})\n",
        "            out=Elt(o)\n",
        "        return out\n",
        "    def fromElt(self,a, checked=True, m=None, untyped=False):\n",
        "        \"\"\"Express a given Elt in our basis\n",
        "           If m is given, we only return level m in terms of our basis of level m.\n",
        "           Unless untyped is set, we assume the coefficients are convertible to float.\n",
        "           When untyped is True, you need to check numpy will still cope, and you get a list.\n",
        "           Unless checked is False, we check that the Elt can fit in the basis.\"\"\"\n",
        "        assert isinstance(a,Elt), a\n",
        "        if checked:\n",
        "            if m is None:\n",
        "                assert len(a.data)<=self.m+1\n",
        "            assert a.maxLetter()<=self.d\n",
        "        if m is not None:\n",
        "            assert m<=self.m\n",
        "        #Something about asserting length\n",
        "        alphabet=list(range(1,self.d+1))\n",
        "        outIdx=0\n",
        "        output_size=self.size() if m is None else self.d**m\n",
        "        if untyped:\n",
        "            #out=np.empty(output_size, dtype=object) #XXX\n",
        "            out=[None]*output_size\n",
        "        else:\n",
        "            out=np.zeros(output_size)\n",
        "        if self.fn!=word2Elt:\n",
        "            R = zip(range(self.m+1),self.data,a.data) if m is None else [(m,self.data[m],a.data[m])] if m<len(a.data) else []\n",
        "            for r,mat,d in R:\n",
        "                x=[float(d.get(Word(i),0)) for i in itertools.product(alphabet,repeat=r)]\n",
        "                v=scipy.linalg.lstsq(mat.T,x)\n",
        "                assert v[2]==mat.shape[1]\n",
        "                newOutIdx=outIdx+mat.shape[0]\n",
        "                out[outIdx:newOutIdx]=v[0]\n",
        "                outIdx=newOutIdx\n",
        "        else:\n",
        "            R=zip(range(self.m+1),a.data) if m is None else [(m,a.data[m])] if m<len(a.data) else []\n",
        "            for r,dd in R:\n",
        "                for a,b in dd.items():\n",
        "                    locidx=0\n",
        "                    for l in a.letters:\n",
        "                        #if checked:\n",
        "                        #    assert 0<l<=self.d\n",
        "                        locidx*=self.d\n",
        "                        locidx+=l-1\n",
        "                    out[outIdx+locidx]=b\n",
        "                outIdx+=self.d**r\n",
        "        return out\n",
        "    def inTermsOf(self,x,l,allowFailure=False):\n",
        "        \"\"\"Express a given Elt (or list of Elts) x as (a) linear combination(s) of the elts in l, \n",
        "           using our basis\"\"\"\n",
        "        single = isinstance(x,Elt)\n",
        "        if not single:\n",
        "            for i in x:\n",
        "                assert isinstance(i, Elt), i\n",
        "        for b in l:\n",
        "            assert isinstance(b,Elt), b\n",
        "        sources = np.array([self.fromElt(b) for b in l])\n",
        "        targets = self.fromElt(x) if single else np.transpose([self.fromElt(i) for i in x])\n",
        "        v=scipy.linalg.lstsq(sources.T,targets)\n",
        "        if not allowFailure:\n",
        "            if v[2]<len(l):\n",
        "                #we are about to assert anyway. Let's be helpful and give some more info\n",
        "                print(\"The l are not linearly independent\")\n",
        "                print(\"There are \"+str(len(l))+\" of them but their span has dimension \"+str(v[2])+\".\")\n",
        "                svd1=scipy.linalg.svd(sources.T)\n",
        "                ##Something like this could get you an example of something in the\n",
        "                ##relevant level but not in the span\n",
        "                ##eg if your focus was on level m with d\n",
        "                ##svd=scipy.linalg.svd(sources.T[(d**m-1):])\n",
        "                ##print(svd[0][-1])\n",
        "                ##print(svd[0][:,-1])\n",
        "                print(\"an example linear dependency is the following combination:\")\n",
        "                for i,j in enumerate(lcm_array(svd1[2][v[2]])):\n",
        "                    if abs(j)>0.001:\n",
        "                        print(i, round(j,3), l[i].pretty())\n",
        "\n",
        "            assert v[2]==len(l)#l is not LI\n",
        "            assert np.amax(v[1])<1e-8#not in span\n",
        "        return v[0] if single else [v[0][:,i] for i in range(v[0].shape[1])]\n",
        "    def matrix(self,l):\n",
        "        \"\"\"return the matrix of the elts in l, \n",
        "           using our basis\"\"\"\n",
        "        for b in l:\n",
        "            assert isinstance(b,Elt), b\n",
        "        sources = np.array([self.fromElt(b) for b in l])\n",
        "        return sources\n",
        "    def rank(self,l):\n",
        "        \"\"\"return the dimension of the span of the elts in l, \n",
        "           using our basis\"\"\"\n",
        "        return np.linalg.matrix_rank(self.matrix(l))\n",
        "\n",
        "    def indicesOfAnagramSet(self, counts, singleLevelOnly):\n",
        "        \"\"\"return the indices of elements which have the homogeneity given by counts\"\"\"\n",
        "        #This currently doesn't depend on self.fn because\n",
        "        #self.fn is always finely homogenous\n",
        "        while len(counts)<self.d:\n",
        "            counts=list(counts)+[0]\n",
        "        assert len(counts)==self.d\n",
        "        level = sum(counts)\n",
        "        assert level <= self.m\n",
        "        o=[]\n",
        "        from itertools import product, chain\n",
        "        alphabet=list(range(1,self.d+1))\n",
        "        target=list(chain.from_iterable([(i,)*j for i,j in zip(alphabet,counts)]))\n",
        "        for i,j in enumerate(itertools.product(alphabet,repeat=level)):\n",
        "            if target == sorted(j):\n",
        "                o.append(i)\n",
        "        if not singleLevelOnly:\n",
        "            offset = indexOfLevelStart(level)\n",
        "            return [offset + i for i in o]\n",
        "        return o                \n",
        "\n",
        "#This function illustrates expressing an Elt which is known to be a Lie element\n",
        "#in terms of a HallBasis. \n",
        "def bch_coefficients(bas):\n",
        "    \"\"\"Return the coefficients of the Baker-Campbell-Hausdorff (BCH)\n",
        "    aka Campbell-Baker-Hausdorff (CBH) formula in the given Hall Basis.\"\"\"\n",
        "    assert isinstance(bas, HallBasis)\n",
        "    assert bas.d==2\n",
        "    x1=exp(letter2Elt(1),maxLevel=bas.m)\n",
        "    x2=exp(letter2Elt(2),maxLevel=bas.m)\n",
        "    x=log(concatenationProduct(x1,x2,maxLevel=bas.m))\n",
        "    out = [ [dotprod(S(foliageFromTree(i),bas),x)\n",
        "              for  i in lev]\n",
        "               for lev in bas.data]\n",
        "    return out\n",
        "\n",
        "###END HALL BASIS STUFF\n",
        "\n",
        "###BEGIN UTILITIES\n",
        "def expandSetsThroughGrading(gradedList,level):\n",
        "    \"\"\"if gradedList is a list of lists, where gradedList[i] is things of weight i+1\n",
        "    returns a list of tuples(representing sets) of things of total weight level\"\"\"\n",
        "    sources=[[(i,j) for j in range(len(gradedList[i]))] for i in range(len(gradedList))]\n",
        "    o=set()\n",
        "    for p in ordered_partitions(level):\n",
        "        if all(i<=len(gradedList) for i in p):\n",
        "            for t in itertools.product(*(sources[i-1] for i in p)):\n",
        "                o.add(tuple(sorted(t)))\n",
        "    return [tuple(gradedList[i][j] for i,j in k) for k in o]\n",
        "\n",
        "def expandThroughGrading(gradedList,level,fn):\n",
        "    \"\"\"if gradedList is a list of lists, where gradedList[i] is things of weight i+1 (*)\n",
        "    returns [fn(t) for t a tuple (representing a set) of things of total weight level]\n",
        "    by \"representing a set\" I mean that fn(t) should give the same value if you permute the elements of t\n",
        "    (*) mnemonic: this function wouldn't be able to do anything with things of weight 0, so it provides no way to supply them!\"\"\"\n",
        "    return [fn(i) for i in expandSetsThroughGrading(gradedList,level)]\n",
        "\n",
        "def signature_of_path_manual(path,m):\n",
        "    \"\"\"calculate the signature of a path, expressed as an Elt\"\"\"\n",
        "    path=np.array(path)\n",
        "    d=path.shape[-1]\n",
        "    if np.shape(path)[0]<2:\n",
        "        return unitElt\n",
        "    displacements = path[1:,:]-path[:-1,:]\n",
        "    displacements2 = [functools.reduce(operator.add,(letter2Elt(i+1)*float(dis[i]) for i in range(d))) for dis in displacements]\n",
        "    sigsOfSegments = [exp(i,m) for i in displacements2]\n",
        "    sig = functools.reduce(lambda x,y: concatenationProduct(x,y,m),sigsOfSegments)\n",
        "    return sig\n",
        "\n",
        "def signature_of_path_iisignature(path,m):\n",
        "    \"\"\"calculate the signature of a path, expressed as an Elt, using iisignature\"\"\"\n",
        "    import iisignature\n",
        "    d=np.shape(path)[-1]\n",
        "    s=iisignature.sig(path,m,1)\n",
        "    letters=range(1,d+1)    \n",
        "    out=[{Word(key):float(val) for key,val in zip(itertools.product(letters,repeat=lev),vals)}\n",
        "              for lev,vals in zip(range(1,m+1),s)]\n",
        "    return Elt([{emptyWord:1}]+out)\n",
        "\n",
        "def countHallWords(d,m):\n",
        "    \"\"\"necklace polynomial: number of hall words at depth m on d letters\"\"\"\n",
        "    return sum(mobius(m//D)*(d**D) for D in divisors(m))/m\n",
        "\n",
        "def expressFunctionInBasis(f,bas,d=None,m=None, basisForImage=None):\n",
        "    \"\"\"if f is a function from Elts to Elts, give the matrix which is its\n",
        "    effect on level m on d letters, in the given basis/ between the given bases\n",
        "    Normally you want to specify m but not d\"\"\"\n",
        "    if basisForImage is None:\n",
        "        basisForImage = bas\n",
        "    if d is None:\n",
        "        d=bas.d\n",
        "    if m is None:\n",
        "        m=bas.m\n",
        "    assert d<=bas.d\n",
        "    assert d<=basisForImage.d\n",
        "    assert m<=bas.m\n",
        "    assert m<=basisForImage.m\n",
        "    alphabet=list(range(1,d+1))\n",
        "    from itertools import product\n",
        "    out=[]\n",
        "    for word in product(alphabet,repeat=m):\n",
        "        elt = bas.fn(word)\n",
        "        im = basisForImage.fromElt(f(elt),m=m)\n",
        "        out.append(im)\n",
        "    return np.array(out).T\n",
        "\n",
        "def lcm_array(x, rounding=2, tol=1e-7):\n",
        "    \"\"\"If x is an array of floats which were a load of integers scaled\n",
        "    by a positive constant, e.g to a unit vector,\n",
        "    try to return an unscaled version, i.e. a multiple of x containing integers.\n",
        "    This is useful if you're in that strange situation where you think SVD\n",
        "    is trying to tell you about a polynomial.\n",
        "    \"\"\"\n",
        "    x=np.array(x)\n",
        "    y_0 = np.unique(sorted([abs(i) for i in x if abs(i)>tol]))\n",
        "    if len(y_0)==0:\n",
        "        return x\n",
        "    y_1=[]\n",
        "    for i in range(len(y_0)):\n",
        "        for j in range(i):\n",
        "            rem = y_0[i]%y_0[j]\n",
        "            if rem>tol:\n",
        "                y_1.append(rem)\n",
        "    y_1 = np.unique(sorted(y_1+list(y_0)))\n",
        "    y_2=[]\n",
        "    for i in range(len(y_1)):\n",
        "        for j in range(i):\n",
        "            rem = y_1[i]%y_1[j]\n",
        "            if rem>tol:\n",
        "                y_2.append(rem)\n",
        "    y_2 = np.unique(sorted(y_2+list(y_1)))\n",
        "    out = x/y_2[0]\n",
        "    if rounding is not None:\n",
        "        out = np.array([round(i,rounding) for i in out])\n",
        "    return out\n",
        "\n",
        "class MaxLevelContext():\n",
        "    \"\"\"Several functions have a maxLevel parameter.\n",
        "    (concatenationProduct, shuffleProduct, log, log1p, exp and their friends)\n",
        "    If you want to fix a maxLevel of say 4 for a block of code do something like this\n",
        "\n",
        "    with MaxLevelContext(4):\n",
        "        Block..\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, level):\n",
        "        self.level = level\n",
        "    def __enter__(self):\n",
        "        global _defaultMaxLevel\n",
        "        self.origMaxLevel = _defaultMaxLevel\n",
        "        _defaultMaxLevel = self.level\n",
        "    def __exit__(self,a,b,c):\n",
        "        global _defaultMaxLevel\n",
        "        _defaultMaxLevel = self.origMaxLevel\n",
        "\n",
        "\n",
        "class UseRationalContext:\n",
        "    \"\"\"If you want this library to use Sympy's rational numbers instead of floating point\n",
        "    during a block, you can do\n",
        "    \n",
        "    with UseRationalContext():\n",
        "         Block..\n",
        "    \"\"\"\n",
        "    def __init__(self, use=True):\n",
        "        self.use = use\n",
        "    def __enter__(self):\n",
        "        global _defaultUseRational\n",
        "        self.origUse=_defaultUseRational\n",
        "        _defaultUseRational = self.use\n",
        "    def __exit__(self,a,b,c):\n",
        "        global _defaultUseRational\n",
        "        _defaultUseRational = self.origUse\n",
        "\n",
        "_expn=dict()\n",
        "def parse(s, sympyCoeffs=False):\n",
        "    \"\"\"parse(\"[3]+2+[4]11\") -> 3*unitElt + word2Elt(\"2\") + 4*word2Elt(\"11\")\"\"\"\n",
        "    global _expn\n",
        "    if sympyCoeffs not in _expn:\n",
        "        import pyparsing as pp\n",
        "\n",
        "        if sympyCoeffs:\n",
        "            from sympy.parsing.sympy_parser import parse_expr\n",
        "            coeff_s = pp.QuotedString(\"[\",endQuoteChar=\"]\")\n",
        "            coeff_s.setParseAction(lambda t: [parse_expr(t[0])])\n",
        "            coeff = pp.Optional(coeff_s,1)\n",
        "        else:\n",
        "            coeff_i=pp.Suppress(\"[\")+pp.Word(pp.nums)+pp.Suppress(\"]\")\n",
        "            coeff_i.setParseAction(lambda t: [int(t[0])])\n",
        "            coeff_f=pp.Suppress(\"[\")+pp.Combine(pp.Optional(pp.Word(pp.nums))+\n",
        "                                                \".\"+\n",
        "                                                pp.Optional(pp.Word(pp.nums)))+pp.Suppress(\"]\")\n",
        "            coeff_f.setParseAction(lambda t: [float(t[0])])\n",
        "            coeff=pp.Optional(coeff_i|coeff_f,1)\n",
        "        if six.PY2:\n",
        "            minus = pp.Literal(\"-\")\n",
        "        else:\n",
        "            #In python 3, where str is unicode, it is easy to allow the minus sign character.\n",
        "            #This means you can copy from a formula in a pdf\n",
        "            minus = pp.Literal(\"-\")|pp.Literal(chr(0x2212))\n",
        "            minus.setParseAction(lambda t:[\"-\"])\n",
        "        firstTerm=pp.Optional(minus,\"+\")+coeff+pp.Optional(pp.Word(pp.nums),\"\")\n",
        "        otherTerm=(pp.Literal(\"+\")|minus)+coeff+pp.Optional(pp.Word(pp.nums),\"\")\n",
        "        _expn[sympyCoeffs] = pp.Group(firstTerm)+pp.ZeroOrMore(pp.Group(otherTerm))\n",
        "    #print(s)\n",
        "    exp=_expn[sympyCoeffs].parseString(s,True)\n",
        "    #print(exp)\n",
        "    x=[(b if a==\"+\" else -b)*word2Elt(c) for a,b,c in exp]\n",
        "    #print(x)\n",
        "    out = functools.reduce(operator.add,x)\n",
        "    return out  \n",
        "\n",
        "def randomLieElt(d,m):\n",
        "    \"\"\"Just a way to make an Elt which is in the FLA, no particular distribution\"\"\"\n",
        "    a = randomElt(d,m)\n",
        "    out = r(a)\n",
        "    return out\n",
        "\n",
        "def randomGrouplikeElt(d,m):\n",
        "    \"\"\"Just a way to make an Elt whose log is in the FLA, no particular distribution\"\"\"\n",
        "    return exp(randomLieElt(d,m))"
      ],
      "metadata": {
        "id": "qUNuV42UK4vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/sherlockery/Signature-Hedging.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUKeLPSEdg66",
        "outputId": "8368d579-910a-4888-bb89-2357c51bff28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Signature-Hedging'...\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install git+https://github.com/crispitagorico/Hall-areas.git\n",
        "\n"
      ],
      "metadata": {
        "id": "kgWApGVoJRIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from math import sqrt\n",
        "from scipy.stats import norm\n",
        "import numpy as np\n",
        "from pylab import plot, show, grid, xlabel, ylabel\n",
        "!pip install iisignature\n",
        "import iisignature\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import statsmodels.api as sm\n",
        "import scipy.stats as stats\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "S6gvXROQ3JVI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "140a9e64-745d-40bf-e35c-b008314ab6c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting iisignature\n",
            "  Downloading iisignature-0.24.tar.gz (1.3 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>1.7 in /usr/local/lib/python3.8/dist-packages (from iisignature) (1.21.6)\n",
            "Building wheels for collected packages: iisignature\n",
            "  Building wheel for iisignature (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iisignature: filename=iisignature-0.24-cp38-cp38-linux_x86_64.whl size=3295670 sha256=97d620784d52cd9ac13ae958ed0c0c9dc26e51419ba2798c6e484760ba5415c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/27/44/79062cc4e18eb42f9ae992a83db3ecfd99d2dff35446daa3f8\n",
            "Successfully built iisignature\n",
            "Installing collected packages: iisignature\n",
            "Successfully installed iisignature-0.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "import sympy as sym\n",
        "import numpy as np\n",
        "import torch"
      ],
      "metadata": {
        "id": "Ua0bceuddH8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def brownian(x0, n, dt, delta, out=None):\n",
        "#     x0 = np.asarray(x0)\n",
        "#     r = norm.rvs(size=x0.shape + (n,), scale=delta*sqrt(dt))\n",
        "#     if out is None:\n",
        "#         out = np.empty(r.shape)\n",
        "#     np.cumsum(r, axis=-1, out=out)\n",
        "#     out += np.expand_dims(x0, axis=-1)\n",
        "    \n",
        "#     return out\n",
        "\n",
        "\n",
        "def brownian(x0, n, dt, out=None):\n",
        "    x0 = np.asarray(x0)\n",
        "    r = norm.rvs(size=x0.shape + (n,), scale=sqrt(dt))\n",
        "    if out is None:\n",
        "        out = np.empty(r.shape)\n",
        "    np.cumsum(r, axis=-1, out=out)\n",
        "    out += np.expand_dims(x0, axis=-1)\n",
        "    return out"
      ],
      "metadata": {
        "id": "tSI8wJ41OATF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# total duration\n",
        "T = 1\n",
        "# steps\n",
        "N = 100\n",
        "# number of simulation\n",
        "m = 1000\n",
        "# Time step size\n",
        "dt = T/N\n",
        "x = np.empty((m,N+1))\n",
        "x0 = 1\n",
        "x[:, 0] = x0\n",
        "r = 0.02\n",
        "\n",
        "brownian(x[:,0], N, dt, out=x[:,1:])\n",
        "for t in range(1, N+1):\n",
        "    x[:,t] /= np.e**(r*t/N*T)\n"
      ],
      "metadata": {
        "id": "gM071a8nMDSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "payoff_vanilla = x[:, -1] - x[:, 0]\n",
        "payoff_asian = np.mean(x[:, 1:], axis=1) -x0"
      ],
      "metadata": {
        "id": "1adyzETyP1rT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(payoff_vanilla[0])\n",
        "\n",
        "print(payoff_asian[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9ZjIFsuZTVI",
        "outputId": "cff7f03a-d362-46d6-9525-56074b6d6c0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3427500477077092\n",
            "-0.04433468492957071\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sig_order_payoff = 1\n",
        "\n",
        "# if lead lag after time, then 4; if lead lag before time, then 3\n",
        "word_dimension = 4"
      ],
      "metadata": {
        "id": "e2xreYuej5o4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lead-lag, then add time\n",
        "sigs = []\n",
        "for i in range(m):\n",
        "    sample = x[i,:].reshape(-1, 1)\n",
        "\n",
        "    ## lead lag before adding time\n",
        "    # sample = np.repeat(sample, 2, axis=0)\n",
        "    # sample = np.column_stack((sample[1:, :], sample[:-1, :]))\n",
        "    # sample = np.column_stack((sample, range(len(sample))))\n",
        "    # sigs.append(iisignature.sig(sample, 2))\n",
        "\n",
        "    # lead lag after adding time\n",
        "    sample = np.column_stack((np.array(range(len(sample))).reshape(-1, 1), sample))\n",
        "    sample = np.repeat(sample, 2, axis=0)\n",
        "    sample = np.column_stack((sample[1:, :], sample[:-1, :]))\n",
        "\n",
        "    _sig = signature_of_path_iisignature(sample, sig_order_payoff)\n",
        "    _sig = np.array([get_coefficient(_sig, Word(w)) for w in wordIter(word_dimension, sig_order_payoff)])\n",
        "    sigs.append(_sig)\n",
        "sigs = np.array(sigs)"
      ],
      "metadata": {
        "id": "G_Wb1kJ8bS-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# signature payoff estimation using linear regression\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(sigs, payoff_vanilla)\n",
        "print(sum(lr_model.predict(sigs) - payoff_vanilla > 1e-6))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Kxgnm3xNCjV",
        "outputId": "7a079aa8-5961-487e-8b91-5b6194113db6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model.intercept_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqTjZd9ZTh8R",
        "outputId": "032dbd86-565e-4538-c28f-07a529317cac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.002549892679792873"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model.coef_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdhitaibX2ud",
        "outputId": "f4a424e4-2123-4993-d188-2516fb2678e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.00000000e+00, 2.54989268e-05, 3.97933041e-01, 0.00000000e+00,\n",
              "       6.02066959e-01])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pay_coeffs = lr_model.coef_\n",
        "# pay_coeffs[:] = 0\n",
        "# pay_coeffs[4] = 1\n",
        "# pay_coeffs"
      ],
      "metadata": {
        "id": "vsjXlcJJZIzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EyDpt0zOntqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(payoff_vanilla[1])\n",
        "print(sigs[1])\n",
        "np.round_(sigs[:, 4], 6) == np.round_(payoff_vanilla, 6)"
      ],
      "metadata": {
        "id": "dzfDmQloV9ei",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a711d28-1ba8-413f-d8a8-e33a5ae9a034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6140435527397023\n",
            "[  1.         100.           0.61404355 100.           0.61404355]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # total duration\n",
        "# T = 1\n",
        "# # steps\n",
        "# N = 100\n",
        "# # number of simulation\n",
        "# m = 1000\n",
        "# # Time step size\n",
        "# dt = T/N\n",
        "# x = np.empty((m,N+1))\n",
        "# x[:, 0] = 100\n",
        "\n",
        "# brownian(x[:,0], N, dt, out=x[:,1:])\n",
        "\n",
        "# diff = np.diff(x)\n",
        "# # test for normally distributed increments\n",
        "# for i in range(m):\n",
        "#     sm.qqplot(diff[0]/np.std(diff[0]) - np.mean(diff[0]), line='45')\n",
        "# # test for independently distributed increments\n",
        "# for n in range(N-2):\n",
        "#     print('n:', n)\n",
        "#     df = pd.DataFrame(diff[:, n:n+2], columns = ['a', 'b'])\n",
        "#     compare = pd.crosstab(df['a'], df['b'])\n",
        "#     chi2, p, dof, ex = stats.chi2_contingency(compare)\n",
        "#     print('p:', p)\n",
        "\n",
        "# delta = 2\n",
        "# # Total time.\n",
        "# T = 1\n",
        "# # Number of steps.\n",
        "# N = 100\n",
        "# # Time step size\n",
        "# dt = T/N\n",
        "# r = 0.02\n",
        "\n",
        "# # # Number of realizations to generate.\n",
        "# # m = 100\n",
        "# # # Create an empty array to store the realizations.\n",
        "# # x = np.empty((m,N+1))\n",
        "# # # Initial values of x.\n",
        "# # x[:, 0] = 100\n",
        "\n",
        "# diff_list = []\n",
        "# for m in [1e2, 1e3, 1e4, 1e5, 1e6]:\n",
        "#     m = int(m)\n",
        "#     print('number of simulations:', m)\n",
        "#     x = np.empty((m,N+1))\n",
        "#     x[:, 0] = 100\n",
        "#     print(x.shape)\n",
        "#     brownian(x[:,0], N, dt, delta, out=x[:,1:])\n",
        "#     for t in range(N+1):\n",
        "#         x[:, t] /= np.e**(r*t/N*T)\n",
        "#     sigs1 =  np.array([iisignature.sig(i.reshape(-1, 1), 6) for i in x])\n",
        "#     m1 = np.mean(sigs1, axis=0)\n",
        "\n",
        "#     brownian(x[:,0], N, dt, delta, out=x[:,1:])\n",
        "#     for t in range(N+1):\n",
        "#         x[:, t] /= np.e**(r*t/N*T)\n",
        "#     sigs2 =  np.array([iisignature.sig(i.reshape(-1, 1), 6) for i in x])\n",
        "#     m2 = np.mean(sigs2, axis=0)\n",
        "#     # print('diff in mean', m1-m2)\n",
        "#     print('proportion of difference in the two computed signature means', (m1-m2)/m1)\n",
        "#     diff_list.append(m1-m2)"
      ],
      "metadata": {
        "id": "Wl9nnRtJgzcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a = word2Elt(\"12\") + word2Elt(\"1\")\n",
        "# b = word2Elt(\"34\")\n",
        "\n",
        "# concatenationProduct(a, b)\n",
        "# get_coefficient(shuffleProduct(a+b,b), Word('124'))\n",
        "# concatenate(Word('12'), Word('45'))\n",
        "# get_coefficient(a, Word('12'))\n",
        "# shuffleProduct(a, word2Elt(Word([])))\n",
        "# isinstance(a,Elt)\n",
        "# epsilon_numeric(shuffleProduct(a, b))\n",
        "# a = Word('2')\n",
        "# e = Word('')\n",
        "# A = word2Elt(a)\n",
        "# E = word2Elt(e)\n",
        "# word2Elt('1') - word2Elt('2')\n",
        "# shuffleProduct(A, E)\n",
        "# p0 = sym.Symbol('p0')\n",
        "# a1 = sym.Symbol('a1')\n",
        "# a2 = sym.Symbol('a2')\n",
        "# element = word2Elt('1') - p0*word2Elt('') - (a1*word2Elt('1') + a2*word2Elt('2'))\n",
        "# element\n",
        "# result = shuffleProduct(element, element)\n",
        "# result\n",
        "# get_coefficient(result, Word('21'))\n",
        "# x1 = sym.Symbol('x1')\n",
        "# y1 = sym.Symbol('y1')"
      ],
      "metadata": {
        "id": "hw-6Ta7Ho16n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a = np.array([sym.Symbol('a'+str(i)) for i in range(3)])\n",
        "# b = np.array([sym.Symbol('b'+str(i)) for i in range(3)])\n",
        "\n",
        "# A = sym.symbols('a0 a1 a2')\n",
        "# a0, a1, a2 = A\n",
        "B = sym.symbols('b0 b1 b2 b3 b4')\n",
        "b0, b1, b2, b3, b4 = B\n",
        "p0 = sym.Symbol('p0')"
      ],
      "metadata": {
        "id": "Z2iCpmYb4wp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pay_coeffs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpJk-pDmd7Gi",
        "outputId": "0ee4694d-4a2b-4135-90f3-67a34f4b27fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.00000000e+00, 2.54989268e-05, 3.97933041e-01, 0.00000000e+00,\n",
              "       6.02066959e-01])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "payoff_word = 0*word2Elt('')\n",
        "for i, w in enumerate(wordIter(word_dimension, sig_order_payoff)):\n",
        "    payoff_word += pay_coeffs[i]*word2Elt(w)\n",
        "payoff_word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJ1dNk7OYaW9",
        "outputId": "82ab86b7-880e-4903-8902-09e9ad689e21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.54989267979289e-05]1+[0.397933040919484]2+[0.602066959080516]4"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# word dimension of the desired hedging strategy l\n",
        "l_dimension = 1"
      ],
      "metadata": {
        "id": "xY98dBnPJvbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l = 0*word2Elt('')\n",
        "for i, w in enumerate(wordIter(word_dimension, l_dimension)):\n",
        "    l += B[i]*word2Elt(w)"
      ],
      "metadata": {
        "id": "jcL0BYDGvrz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXldcZiSxG8V",
        "outputId": "c13269c1-6e72-4fef-c158-58ff37b612fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[b0]+[b1]1+[b2]2+[b3]3+[b4]4"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if word dimension of the signatures is 3, then change '4' to '3' below\n",
        "plynm = payoff_word - p0*word2Elt('') - concatenationProduct(l, word2Elt('4'))\n",
        "plynm"
      ],
      "metadata": {
        "id": "2dQ57xHL490V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9b47292-0afc-4356-99c5-f2f4c9044199"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-p0]\n",
              "+[2.54989267979289e-05]1\n",
              "+[0.397933040919484]2\n",
              "+[0.602066959080516 - b0]4\n",
              "+[-b1]14\n",
              "+[-b2]24\n",
              "+[-b3]34\n",
              "+[-b4]44"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# shuffle polynomial of degree 2\n",
        "poly = shuffleProduct(plynm, plynm)\n",
        "# poly = plynm\n",
        "poly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPenlYOidTc7",
        "outputId": "42f809e7-2482-43d7-e27d-019d0f321f30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[p0**2]\n",
              "+[-5.09978535958577e-5*p0]1\n",
              "+[-0.795866081838968*p0]2\n",
              "+[-2*p0*(0.602066959080516 - b0)]4\n",
              "+[1.30039053569227e-09]11\n",
              "+[2.02937309617663e-05]12\n",
              "+[-5.09978535958577e-5*b0 + 2*b1*p0 + 3.07041226340914e-5]14\n",
              "+[2.02937309617663e-05]21\n",
              "+[0.316701410110855]22\n",
              "+[-0.795866081838968*b0 + 2*b2*p0 + 0.479164671728113]24\n",
              "+[2*b3*p0]34\n",
              "+[3.07041226340914e-5 - 5.09978535958577e-5*b0]41\n",
              "+[0.479164671728113 - 0.795866081838968*b0]42\n",
              "+[2*b4*p0 + 2*(0.602066959080516 - b0)**2]44\n",
              "+[-0.000101995707191715*b1]114\n",
              "+[-0.795866081838968*b1 - 5.09978535958577e-5*b2]124\n",
              "+[-5.09978535958577e-5*b3]134\n",
              "+[-5.09978535958577e-5*b1]141\n",
              "+[-0.795866081838968*b1]142\n",
              "+[-4*b1*(0.602066959080516 - b0) - 5.09978535958577e-5*b4]144\n",
              "+[-0.795866081838968*b1 - 5.09978535958577e-5*b2]214\n",
              "+[-1.59173216367794*b2]224\n",
              "+[-0.795866081838968*b3]234\n",
              "+[-5.09978535958577e-5*b2]241\n",
              "+[-0.795866081838968*b2]242\n",
              "+[-4*b2*(0.602066959080516 - b0) - 0.795866081838968*b4]244\n",
              "+[-5.09978535958577e-5*b3]314\n",
              "+[-0.795866081838968*b3]324\n",
              "+[-5.09978535958577e-5*b3]341\n",
              "+[-0.795866081838968*b3]342\n",
              "+[-4*b3*(0.602066959080516 - b0)]344\n",
              "+[-2*b1*(0.602066959080516 - b0) - 5.09978535958577e-5*b4]414\n",
              "+[-2*b2*(0.602066959080516 - b0) - 0.795866081838968*b4]424\n",
              "+[-2*b3*(0.602066959080516 - b0)]434\n",
              "+[-5.09978535958577e-5*b4]441\n",
              "+[-0.795866081838968*b4]442\n",
              "+[-6*b4*(0.602066959080516 - b0)]444\n",
              "+[4*b1**2]1144\n",
              "+[4*b1*b2]1244\n",
              "+[4*b1*b3]1344\n",
              "+[2*b1**2]1414\n",
              "+[2*b1*b2]1424\n",
              "+[2*b1*b3]1434\n",
              "+[6*b1*b4]1444\n",
              "+[4*b1*b2]2144\n",
              "+[4*b2**2]2244\n",
              "+[4*b2*b3]2344\n",
              "+[2*b1*b2]2414\n",
              "+[2*b2**2]2424\n",
              "+[2*b2*b3]2434\n",
              "+[6*b2*b4]2444\n",
              "+[4*b1*b3]3144\n",
              "+[4*b2*b3]3244\n",
              "+[4*b3**2]3344\n",
              "+[2*b1*b3]3414\n",
              "+[2*b2*b3]3424\n",
              "+[2*b3**2]3434\n",
              "+[6*b3*b4]3444\n",
              "+[4*b1*b4]4144\n",
              "+[4*b2*b4]4244\n",
              "+[4*b3*b4]4344\n",
              "+[2*b1*b4]4414\n",
              "+[2*b2*b4]4424\n",
              "+[2*b3*b4]4434\n",
              "+[6*b4**2]4444"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = x*1e-1"
      ],
      "metadata": {
        "id": "Ips6kPKelVAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# expected signature order\n",
        "exp_sig_order = 4\n",
        "\n",
        "# Compute expected signatures\n",
        "# lead-lag, then add time\n",
        "exp_sigs = []\n",
        "for i in range(m):\n",
        "    sample = x1[i,:].reshape(-1, 1)\n",
        "\n",
        "    ## lead lag before adding time\n",
        "    # sample = np.repeat(sample, 2, axis=0)\n",
        "    # sample = np.column_stack((sample[1:, :], sample[:-1, :]))\n",
        "    # sample = np.column_stack((sample, range(len(sample))))\n",
        "    # sigs.append(iisignature.sig(sample, 2))\n",
        "\n",
        "    # lead lag after adding time\n",
        "    sample = np.column_stack((np.array(range(len(sample))).reshape(-1, 1), sample))\n",
        "    sample = np.repeat(sample, 2, axis=0)\n",
        "    sample = np.column_stack((sample[1:, :], sample[:-1, :]))\n",
        "\n",
        "    _sig = signature_of_path_iisignature(sample, exp_sig_order)\n",
        "    _sig = np.array([get_coefficient(_sig, Word(w)) for w in wordIter(word_dimension, exp_sig_order)])\n",
        "    exp_sigs.append(_sig)\n",
        "exp_sigs = np.array(exp_sigs)\n",
        "expected_sigs = exp_sigs.mean(axis=0)\n",
        "# _w = wordIter(word_dimension, sig_order_payoff)\n",
        "exp_sigs_elt = 0*word2Elt('')\n",
        "for i, w in enumerate(wordIter(word_dimension, exp_sig_order)):\n",
        "    exp_sigs_elt += expected_sigs[i]*word2Elt(w)"
      ],
      "metadata": {
        "id": "cGIyiyfiZL9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.figure(1)\n",
        "# for i in range(len(x1)):\n",
        "#     plt.plot(x1[i])"
      ],
      "metadata": {
        "id": "YvHeiXG8k41d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute the target minimising polynomial in terms of the unknown minimisers\n",
        "min_poly = dotprod(poly, exp_sigs_elt)\n",
        "min_poly = min_poly.subs(p0,1)\n",
        "# min_poly = b0**2 + (b1-3)**2 + 6*(p0-3)**4"
      ],
      "metadata": {
        "id": "YQ_2u2htqM_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_poly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "99WPbeh6ktbO",
        "outputId": "7468adef-c8c1-48db-a976-9c598e1d5312"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.0131470472421143*b0 + 31.8837546995012*b1**2 - 0.00209026285735786*b1*b2 + 63.2986575448969*b1*b3 - 0.00164246953184658*b1*b4 - 0.937703708210829*b1*(0.602066959080516 - b0) - 0.53895845469741*b1 + 0.000134959061664703*b2**2 - 0.00206474816401002*b2*b3 + 0.000176029438353144*b2*b4 + 5.10293866956643e-5*b2*(0.602066959080516 - b0) + 0.0189792575961964*b2 + 31.4172230445348*b3**2 - 0.00162997777503217*b3*b4 - 0.928422911654704*b3*(0.602066959080516 - b0) - 0.532384931076353*b3 + 6.51438370503757e-5*b4**2 + 2.49835136288156e-5*b4*(0.602066959080516 - b0) + 0.00926707328647585*b4 + 0.00928079655612579*(0.602066959080516 - b0)**2 + 1.00658414315707"
            ],
            "text/latex": "$\\displaystyle - 0.0131470472421143 b_{0} + 31.8837546995012 b_{1}^{2} - 0.00209026285735786 b_{1} b_{2} + 63.2986575448969 b_{1} b_{3} - 0.00164246953184658 b_{1} b_{4} - 0.937703708210829 b_{1} \\left(0.602066959080516 - b_{0}\\right) - 0.53895845469741 b_{1} + 0.000134959061664703 b_{2}^{2} - 0.00206474816401002 b_{2} b_{3} + 0.000176029438353144 b_{2} b_{4} + 5.10293866956643 \\cdot 10^{-5} b_{2} \\left(0.602066959080516 - b_{0}\\right) + 0.0189792575961964 b_{2} + 31.4172230445348 b_{3}^{2} - 0.00162997777503217 b_{3} b_{4} - 0.928422911654704 b_{3} \\left(0.602066959080516 - b_{0}\\right) - 0.532384931076353 b_{3} + 6.51438370503757 \\cdot 10^{-5} b_{4}^{2} + 2.49835136288156 \\cdot 10^{-5} b_{4} \\left(0.602066959080516 - b_{0}\\right) + 0.00926707328647585 b_{4} + 0.00928079655612579 \\left(0.602066959080516 - b_{0}\\right)^{2} + 1.00658414315707$"
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.figure(1)\n",
        "# x = np.linspace(1, 8, 1000)\n",
        "# plt.plot(x, -(x-4)**3 + (x-2)**2 +2)\n",
        "# plt.show"
      ],
      "metadata": {
        "id": "S_-RgTXeBvQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# turn the expression in sympy to optimisable function\n",
        "poly_func = sym.lambdify([B], min_poly)"
      ],
      "metadata": {
        "id": "nKx-mnA0tZIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f_lambda(_l):\n",
        "    return poly_func(_l)"
      ],
      "metadata": {
        "id": "3FHQB8oxufjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f_lambda([0,0,0,0,0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gilF7ChD-Vrw",
        "outputId": "871ae709-1ae3-40f6-8447-40333e7bbbb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0099482891998657"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cOdEYktzmvR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimising by gradient descent\n",
        "# ll = torch.rand(5, requires_grad=True)\n",
        "# ll = torch.tensor([0.0,0.0,0.0,0.0,0.0], requires_grad=True)\n",
        "# ll.data = ll.data*(-513324)\n",
        "# pp = torch.rand(1, requires_grad=True)\n",
        "# pp.data = pp.data*(-32426)\n",
        "\n",
        "ll = torch.ones(5, requires_grad=True)\n",
        "print(ll)\n",
        "# print(pp)\n",
        "step_size = 0.0001\n",
        "n_iter = 1000\n",
        "\n",
        "loss_list = []\n",
        "ll_list = []\n",
        "for i in range(n_iter):\n",
        "    f_val = f_lambda(ll)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        ll_list.append(ll.data.numpy())\n",
        "        loss_list.append(f_val.data)\n",
        "    f_val.backward()\n",
        "    ll.data = ll.data - step_size * ll.grad.data\n",
        "    # pp.data = pp.data - step_size * pp.grad.data\n",
        "    ll.grad.data.zero_()\n",
        "    # pp.grad.data.zero_()"
      ],
      "metadata": {
        "id": "98vndV4Yu4e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e1cd2f3-d021-430d-ce78-4225d426a352"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.plot(loss_list)\n",
        "for i in range(len(ll_list[0])):\n",
        "    plt.plot(np.array(ll_list)[:, i], label=i)\n",
        "plt.legend()\n",
        "\n",
        "plt.figure(2)\n",
        "plt.plot(loss_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "rakIXTLqoUTE",
        "outputId": "ba48f3a7-a01c-4905-cf7d-ad176c58f026"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f2a5c28e280>]"
            ]
          },
          "metadata": {},
          "execution_count": 140
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ll.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcE1bSrsoUz7",
        "outputId": "c58da295-0473-4bf3-eee3-feaba3fb7577"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  -511.8735, -23543.0000,  14502.1270, -23306.9551,   7154.0786])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pp.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGAOUSvyvlW-",
        "outputId": "d68913f2-a864-4547-fd5e-d2cfcec0d111"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([14993.7656])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from scipy.optimize import minimize"
      ],
      "metadata": {
        "id": "3YCVvAz-txdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def min_func(x, poly):\n",
        "#     return poly.subs([(p0, x[0]), (a[0], x[1]), (a[1], x[2]), (a[2], x[3]), (b[0], x[4]), (b[1], x[5]), (b[2], x[6])])"
      ],
      "metadata": {
        "id": "odRRbPShv68u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x0 = np.array([1,2,3,4,5,6,7], dtype='float')\n",
        "# # min_x_NM = minimize(min_func, x0, min_poly, method='Nelder-Mead', tol=1e-6)\n",
        "# # min_x_TNC = minimize(min_func, x0, min_poly, method='TNC', tol=1e-6)\n",
        "# min_x_NM_bound = minimize(min_func, x0, min_poly, method='Nelder-Mead', bounds=[(1, 10) for i in range(7)], tol=1e-6)\n",
        "# min_x_TNC_bound = minimize(min_func, x0, min_poly, method='TNC', bounds=[(1, 10) for i in range(7)], tol=1e-6)"
      ],
      "metadata": {
        "id": "ix6g79PHwMg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# min_x_NM_bound"
      ],
      "metadata": {
        "id": "o0gqi3Tu3gjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_x_TNC_bound"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzEmSdKByW51",
        "outputId": "a581adab-ead4-4ac1-ef7c-d409f2d8da73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     fun: -2362.76696838211\n",
              "     jac: array([ 2.62529740e+02, -2.62529717e+02,  4.54747354e-05,  0.00000000e+00,\n",
              "        0.00000000e+00, -1.22501559e+02, -1.13775140e+02])\n",
              " message: 'Converged (|f_n-f_(n-1)| ~= 0)'\n",
              "    nfev: 536\n",
              "     nit: 8\n",
              "  status: 1\n",
              " success: True\n",
              "       x: array([ 1.        , 10.        ,  3.23834289,  4.22009754,  4.92715999,\n",
              "       10.        , 10.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# min_x_TNC"
      ],
      "metadata": {
        "id": "Yp6XBbs71J-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gradient descent\n"
      ],
      "metadata": {
        "id": "T0z-lkFI2joW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        " \n",
        "# # Creating a function f(X) with a slope of -5\n",
        "# X = torch.arange(-5, 5, 0.1).view(-1, 1)\n",
        "# func = -5 * X\n",
        " \n",
        "# # Adding Gaussian noise to the function f(X) and saving it in Y\n",
        "# Y = func + 0.4 * torch.randn(X.size())"
      ],
      "metadata": {
        "id": "2Vj6yF4CM67h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1., 2.], requires_grad=True)\n",
        "y = 4*x[0]*x[1]+7*x[0]"
      ],
      "metadata": {
        "id": "pyAARsOMhukt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.grad"
      ],
      "metadata": {
        "id": "6URP5L7Bhv5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(para):\n",
        "    return para[0]*para[2]-para[1]*para[3]"
      ],
      "metadata": {
        "id": "KR3PjNMZjGrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = forward(para)"
      ],
      "metadata": {
        "id": "rre4JOiAhwPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = sym.Symbol('a')\n",
        "expr = a**2+3"
      ],
      "metadata": {
        "id": "VVKBBSJwhwk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "expr.subs(a, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "LHt5ajYAhwxF",
        "outputId": "3d3858d2-7436-4d2c-981f-723c5edf9728"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ],
            "text/latex": "$\\displaystyle 12$"
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min_poly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 61
        },
        "id": "kxNi9NBOhw6f",
        "outputId": "9e0726d2-3367-40ba-a1cf-9b1fd6b3ee93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.629991111344289*a1**2 - 1.58743958794568*a1*(a0 - p0) + 1.25998222268858*a1*(a2 - b0) - 1.70185953707389*b1*(a0 - p0) - 0.629991111344289*b2*(a0 - p0) + (a0 - p0)**2 - 1.58743958794568*(a0 - p0)*(a2 - b0) + 0.629991111344289*(a2 - b0)**2"
            ],
            "text/latex": "$\\displaystyle 0.629991111344289 a_{1}^{2} - 1.58743958794568 a_{1} \\left(a_{0} - p_{0}\\right) + 1.25998222268858 a_{1} \\left(a_{2} - b_{0}\\right) - 1.70185953707389 b_{1} \\left(a_{0} - p_{0}\\right) - 0.629991111344289 b_{2} \\left(a_{0} - p_{0}\\right) + \\left(a_{0} - p_{0}\\right)^{2} - 1.58743958794568 \\left(a_{0} - p_{0}\\right) \\left(a_{2} - b_{0}\\right) + 0.629991111344289 \\left(a_{2} - b_{0}\\right)^{2}$"
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gia87UjIhxCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_poly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 61
        },
        "id": "iVR4WmnZazxv",
        "outputId": "9b64e11d-e82f-407e-e96c-b408f891503f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.629991111344289*a1**2 - 1.58743958794568*a1*(a0 - p0) + 1.25998222268858*a1*(a2 - b0) - 1.70185953707389*b1*(a0 - p0) - 0.629991111344289*b2*(a0 - p0) + (a0 - p0)**2 - 1.58743958794568*(a0 - p0)*(a2 - b0) + 0.629991111344289*(a2 - b0)**2"
            ],
            "text/latex": "$\\displaystyle 0.629991111344289 a_{1}^{2} - 1.58743958794568 a_{1} \\left(a_{0} - p_{0}\\right) + 1.25998222268858 a_{1} \\left(a_{2} - b_{0}\\right) - 1.70185953707389 b_{1} \\left(a_{0} - p_{0}\\right) - 0.629991111344289 b_{2} \\left(a_{0} - p_{0}\\right) + \\left(a_{0} - p_{0}\\right)^{2} - 1.58743958794568 \\left(a_{0} - p_{0}\\right) \\left(a_{2} - b_{0}\\right) + 0.629991111344289 \\left(a_{2} - b_{0}\\right)^{2}$"
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.tensor([0.0 for i in range(7)], requires_grad=True)\n",
        "# Y = min_func(X, min_poly)"
      ],
      "metadata": {
        "id": "E37fqiYca6l2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(x):\n",
        "    return min_poly.subs(zip(min_poly.free_symbols, x))"
      ],
      "metadata": {
        "id": "l9tJMlLOc_I_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "para = torch.tensor([0.0 for i in range(7)], requires_grad=True)\n",
        "step_size = 0.1\n",
        "loss_GD = []\n",
        "n_iter = 20"
      ],
      "metadata": {
        "id": "edNDUYsCdsCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "para"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AwLzHwKfsbq",
        "outputId": "ceeb7162-e194-4c98-e605-5697e9c574cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0.], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range (n_iter):\n",
        "\n",
        "    # calculating the loss between original and predicted data points\n",
        "    loss = forward(para)\n",
        "    # backward pass for computing the gradients of the loss w.r.t to learnable parameters\n",
        "    loss.backward()\n",
        "    # updateing the parameters after each iteration\n",
        "    para.data = para.data - step_size * para.grad.data\n",
        "    # zeroing gradients after each iteration\n",
        "    para.grad.data.zero_()\n",
        "    # priting the values for understanding\n",
        "    print('{}, \\t{}, \\t{}, \\t{}'.format(i, loss.item(), para.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "Fwh84VFgNEC7",
        "outputId": "fa3a4f2c-0876-47d0-9cbd-6a4ec8a27160"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-103-ac801d238545>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpara\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# backward pass for computing the gradients of the loss w.r.t to learnable parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m# updateing the parameters after each iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mpara\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpara\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstep_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpara\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# defining the function for forward pass for prediction\n",
        "def forward(x):\n",
        "    return w * x + b\n",
        " \n",
        "# evaluating data points with Mean Square Error (MSE)\n",
        "def criterion(y_pred, y):\n",
        "    return torch.mean((y_pred - y) ** 2)\n",
        "\n",
        "w = torch.tensor(-10.0, requires_grad=True)\n",
        "b = torch.tensor(-20.0, requires_grad=True)\n",
        " \n",
        "step_size = 0.1\n",
        "loss_BGD = []\n",
        "n_iter = 20\n",
        "\n",
        "for i in range (n_iter):\n",
        "    # making predictions with forward pass\n",
        "    Y_pred = forward(X)\n",
        "    # calculating the loss between original and predicted data points\n",
        "    loss = criterion(Y_pred, Y)\n",
        "    # storing the calculated loss in a list\n",
        "    loss_BGD.append(loss.item())\n",
        "    # backward pass for computing the gradients of the loss w.r.t to learnable parameters\n",
        "    loss.backward()\n",
        "    # updateing the parameters after each iteration\n",
        "    w.data = w.data - step_size * w.grad.data\n",
        "    b.data = b.data - step_size * b.grad.data\n",
        "    # zeroing gradients after each iteration\n",
        "    w.grad.data.zero_()\n",
        "    b.grad.data.zero_()\n",
        "    # priting the values for understanding\n",
        "    print('{}, \\t{}, \\t{}, \\t{}'.format(i, loss.item(), w.item(), b.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vxkFnMMNM_E",
        "outputId": "872c9e35-d4e6-430f-e235-c8a1050645e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0, \t597.9834594726562, \t-1.8522615432739258, \t-16.05585479736328\n",
            "1, \t344.2311706542969, \t-7.247360706329346, \t-12.819061279296875\n",
            "2, \t203.22259521484375, \t-3.616461992263794, \t-10.283576965332031\n",
            "3, \t122.49346923828125, \t-6.012916564941406, \t-8.218880653381348\n",
            "4, \t75.0594253540039, \t-4.393834590911865, \t-6.59108829498291\n",
            "5, \t46.58382797241211, \t-5.457484245300293, \t-5.272663116455078\n",
            "6, \t29.1961612701416, \t-4.7348456382751465, \t-4.228559494018555\n",
            "7, \t18.43986701965332, \t-5.206404685974121, \t-3.3860504627227783\n",
            "8, \t11.720961570739746, \t-4.883449554443359, \t-2.7167587280273438\n",
            "9, \t7.494123458862305, \t-5.092167854309082, \t-2.178095817565918\n",
            "10, \t4.821413516998291, \t-4.947566032409668, \t-1.7492527961730957\n",
            "11, \t3.1252400875091553, \t-5.039727210998535, \t-1.404732346534729\n",
            "12, \t2.0460243225097656, \t-4.974810600280762, \t-1.130037546157837\n",
            "13, \t1.3581095933914185, \t-5.015362739562988, \t-0.9096325635910034\n",
            "14, \t0.9190599322319031, \t-4.986110687255859, \t-0.7337141036987305\n",
            "15, \t0.6385950446128845, \t-5.003862380981445, \t-0.5926867723464966\n",
            "16, \t0.4593227803707123, \t-4.990611553192139, \t-0.48004239797592163\n",
            "17, \t0.34468182921409607, \t-4.998323440551758, \t-0.3897944986820221\n",
            "18, \t0.27135059237480164, \t-4.992277145385742, \t-0.3176731765270233\n",
            "19, \t0.22443251311779022, \t-4.995588779449463, \t-0.2599157691001892\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plynm.coeffApply()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u06wenuRNOxU",
        "outputId": "525f2017-aed5-4776-ee8c-3790331a1d75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[a0 - p0]+[a1]1+[a2 - b0]2+[-b1]12+[-b2]22"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "free_symbol_set = min_poly.free_symbols"
      ],
      "metadata": {
        "id": "HqgmqRfPo2E0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = lambdify(((x, y, z),), min_poly(a))"
      ],
      "metadata": {
        "id": "Qh8WScfDnlZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zip(free_symbol_set, np.array([0 for i in range(7)]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oogrF_PLpeiD",
        "outputId": "32245ced-46e7-4791-eef1-d934133bd7d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<zip at 0x7f4b118c5a80>"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, j in zip(free_symbol_set, np.array([0 for i in range(7)])):\n",
        "    print(i, j)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuA5_m_6pmtK",
        "outputId": "36bbc8cc-f20e-42b8-9e87-83e144f51952"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b0 0\n",
            "a0 0\n",
            "b2 0\n",
            "p0 0\n",
            "a1 0\n",
            "a2 0\n",
            "b1 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = sym.lambdify(list(free_symbol_set), min_poly)"
      ],
      "metadata": {
        "id": "h7MIwF0ApqNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f(np.array([0 for i in range(7)]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "BwVvjD1nrUJs",
        "outputId": "280d8621-7d5c-43a6-f987-9739f4e77c8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-141-ad406c222a35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: _lambdifygenerated() missing 6 required positional arguments: 'a0', 'b2', 'p0', 'a1', 'a2', and 'b1'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "forward(np.array([0 for i in range(7)]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "lkuvvwJjqAOk",
        "outputId": "e2ed8800-5f43-4648-c19e-79748efb2ca8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ],
            "text/latex": "$\\displaystyle 0$"
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x = sym.symbols('x0 x1')\n",
        "x0, x1 = x\n",
        "y = sym.symbols('y0 y1')\n",
        "y0, y1 = y\n",
        "expr = x0*y0 + x1*y1\n",
        "# f = lambda x: x**2\n",
        "f1 = sym.lambdify([x, y], expr)"
      ],
      "metadata": {
        "id": "N4VS9C1SqEiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1([1,2],[3,4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIDI-pKEpyqG",
        "outputId": "dbb3b36d-9cf1-4b17-ff36-f6ce8f2c6fdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min_poly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 61
        },
        "id": "tLfx2JOjqBiQ",
        "outputId": "dbe93e7f-1886-4d58-f33c-a91346b4066b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.25705482345182*a1**2 - 3.60946246604772*a1*(a0 - p0) + 6.51410964690363*a1*(a2 - b0) - 4.24126729947389*b1*(a0 - p0) - 3.25705482345182*b2*(a0 - p0) + (a0 - p0)**2 - 3.60946246604772*(a0 - p0)*(a2 - b0) + 3.25705482345182*(a2 - b0)**2"
            ],
            "text/latex": "$\\displaystyle 3.25705482345182 a_{1}^{2} - 3.60946246604772 a_{1} \\left(a_{0} - p_{0}\\right) + 6.51410964690363 a_{1} \\left(a_{2} - b_{0}\\right) - 4.24126729947389 b_{1} \\left(a_{0} - p_{0}\\right) - 3.25705482345182 b_{2} \\left(a_{0} - p_{0}\\right) + \\left(a_{0} - p_{0}\\right)^{2} - 3.60946246604772 \\left(a_{0} - p_{0}\\right) \\left(a_{2} - b_{0}\\right) + 3.25705482345182 \\left(a_{2} - b_{0}\\right)^{2}$"
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DHzHW9YJs9Vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1([0,0,0], [0,0,0], 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-e0Is1pctFtG",
        "outputId": "0c7333c6-50b4-40ac-ce87-11b1ceb5072a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16.0"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quadratic hedging of asian option under black scholes\n",
        "\n",
        "compute pnl compute sharpe ratio"
      ],
      "metadata": {
        "id": "9JSGVBiBtKge"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}